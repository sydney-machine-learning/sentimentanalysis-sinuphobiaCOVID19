{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6mcZK_I-_OXK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mcZK_I-_OXK",
    "outputId": "142085ab-4b37-4c48-cc1c-3813629433d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.10.0 in d:\\anaconda\\envs\\py39\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (1.24.4)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (2023.12.25)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (2.32.3)\n",
      "Requirement already satisfied: sacremoses in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (0.1.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from huggingface-hub>=0.0.12->transformers==4.10.0) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from huggingface-hub>=0.0.12->transformers==4.10.0) (4.10.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\py39\\lib\\site-packages (from tqdm>=4.27->transformers==4.10.0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from requests->transformers==4.10.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from requests->transformers==4.10.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from requests->transformers==4.10.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from requests->transformers==4.10.0) (2024.2.2)\n",
      "Requirement already satisfied: click in d:\\anaconda\\envs\\py39\\lib\\site-packages (from sacremoses->transformers==4.10.0) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\envs\\py39\\lib\\site-packages (from sacremoses->transformers==4.10.0) (1.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd9a0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "NMK4CvTko7Dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NMK4CvTko7Dd",
    "outputId": "4332d180-f5fb-4a59-98d5-03f575bb53bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformersNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Version: 4.10.0\n",
      "Summary: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Sam Shleifer, Patrick von Platen, Sylvain Gugger, Suraj Patil, Stas Bekman, Google AI Language Team Authors, Open AI team Authors, Facebook AI Authors, Carnegie Mellon University Authors\n",
      "Author-email: thomas@huggingface.co\n",
      "License: Apache\n",
      "Location: d:\\anaconda\\envs\\py39\\lib\\site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, sacremoses, tokenizers, tqdm\n",
      "Required-by: sentence-transformers\n"
     ]
    }
   ],
   "source": [
    "pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7aa1a2-4ba4-4a43-8aab-bd1ad3beab7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af7aa1a2-4ba4-4a43-8aab-bd1ad3beab7a",
    "outputId": "dca5a64e-2a21-43f7-c5de-dc1cfc7b3851"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import demoji\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/sydney-machine-learning/sentimentanalysis-sinuphobiaCOVID19/main/Sample_OriginalDataset/Sample_Australia.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc599e4-f3a5-4de7-bea0-0cfdfb0f1c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Wed Dec 08 04:25:46 +0000 2021</td>\n",
       "      <td>1468436616263909377</td>\n",
       "      <td>RT @AaronSiriSG: Litigation update:  \\n\\nFDA d...</td>\n",
       "      <td>Iasi, Romania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>229</td>\n",
       "      <td>Wed Dec 08 04:25:57 +0000 2021</td>\n",
       "      <td>1468436661633630209</td>\n",
       "      <td>RT @covidbaseau: The TGA has approved the Mode...</td>\n",
       "      <td>Canberra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>236</td>\n",
       "      <td>Wed Dec 08 04:26:06 +0000 2021</td>\n",
       "      <td>1468436701043314692</td>\n",
       "      <td>RT @SimoLove: Federal Health Minister Greg Hun...</td>\n",
       "      <td>Wurundjeri Richmond, Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250</td>\n",
       "      <td>Wed Dec 08 04:26:07 +0000 2021</td>\n",
       "      <td>1468436704755286020</td>\n",
       "      <td>@twityouse Are these the deniers that are wear...</td>\n",
       "      <td>Victoria, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>257</td>\n",
       "      <td>Wed Dec 08 04:26:07 +0000 2021</td>\n",
       "      <td>1468436706424545281</td>\n",
       "      <td>RT @drsimonegold: WOW: a preprint study for Th...</td>\n",
       "      <td>Perth WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3010</td>\n",
       "      <td>Wed Dec 08 04:29:40 +0000 2021</td>\n",
       "      <td>1468437598301351936</td>\n",
       "      <td>RT @SimoLove: On Novak Djokovic, Federal Healt...</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3046</td>\n",
       "      <td>Wed Dec 08 04:29:51 +0000 2021</td>\n",
       "      <td>1468437645348929539</td>\n",
       "      <td>RT @GemmaTognini: Their son who lived in WA to...</td>\n",
       "      <td>Kardinya, Perth (WA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3056</td>\n",
       "      <td>Wed Dec 08 04:29:48 +0000 2021</td>\n",
       "      <td>1468437630828253185</td>\n",
       "      <td>RT @TheEconomist: Just one month ago, South Af...</td>\n",
       "      <td>Penrith area, NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3094</td>\n",
       "      <td>Wed Dec 08 04:29:52 +0000 2021</td>\n",
       "      <td>1468437650801512450</td>\n",
       "      <td>RT @zerohedge: Vietnam Province Suspends Pfize...</td>\n",
       "      <td>Victoria, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3104</td>\n",
       "      <td>Wed Dec 08 04:29:51 +0000 2021</td>\n",
       "      <td>1468437647110512641</td>\n",
       "      <td>Neil Young Says He and Daryl Hannah Enjoyed 'J...</td>\n",
       "      <td>Gold Coast, Queensland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                      created_at                   id  \\\n",
       "0           11  Wed Dec 08 04:25:46 +0000 2021  1468436616263909377   \n",
       "1          229  Wed Dec 08 04:25:57 +0000 2021  1468436661633630209   \n",
       "2          236  Wed Dec 08 04:26:06 +0000 2021  1468436701043314692   \n",
       "3          250  Wed Dec 08 04:26:07 +0000 2021  1468436704755286020   \n",
       "4          257  Wed Dec 08 04:26:07 +0000 2021  1468436706424545281   \n",
       "..         ...                             ...                  ...   \n",
       "95        3010  Wed Dec 08 04:29:40 +0000 2021  1468437598301351936   \n",
       "96        3046  Wed Dec 08 04:29:51 +0000 2021  1468437645348929539   \n",
       "97        3056  Wed Dec 08 04:29:48 +0000 2021  1468437630828253185   \n",
       "98        3094  Wed Dec 08 04:29:52 +0000 2021  1468437650801512450   \n",
       "99        3104  Wed Dec 08 04:29:51 +0000 2021  1468437647110512641   \n",
       "\n",
       "                                                 text  \\\n",
       "0   RT @AaronSiriSG: Litigation update:  \\n\\nFDA d...   \n",
       "1   RT @covidbaseau: The TGA has approved the Mode...   \n",
       "2   RT @SimoLove: Federal Health Minister Greg Hun...   \n",
       "3   @twityouse Are these the deniers that are wear...   \n",
       "4   RT @drsimonegold: WOW: a preprint study for Th...   \n",
       "..                                                ...   \n",
       "95  RT @SimoLove: On Novak Djokovic, Federal Healt...   \n",
       "96  RT @GemmaTognini: Their son who lived in WA to...   \n",
       "97  RT @TheEconomist: Just one month ago, South Af...   \n",
       "98  RT @zerohedge: Vietnam Province Suspends Pfize...   \n",
       "99  Neil Young Says He and Daryl Hannah Enjoyed 'J...   \n",
       "\n",
       "                     user_location  \n",
       "0                    Iasi, Romania  \n",
       "1                         Canberra  \n",
       "2   Wurundjeri Richmond, Melbourne  \n",
       "3              Victoria, Australia  \n",
       "4                         Perth WA  \n",
       "..                             ...  \n",
       "95                       Melbourne  \n",
       "96            Kardinya, Perth (WA)  \n",
       "97               Penrith area, NSW  \n",
       "98             Victoria, Australia  \n",
       "99          Gold Coast, Queensland  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "448f1759",
   "metadata": {
    "id": "448f1759"
   },
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "df = df.drop(columns=['Unnamed: 0', 'id', 'user_location'])\n",
    "\n",
    "df = df.dropna(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "072a4554-69a2-44a8-8227-0f3fd5d40769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Dec 08 04:25:46 +0000 2021</td>\n",
       "      <td>RT @AaronSiriSG: Litigation update:  \\n\\nFDA d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed Dec 08 04:25:57 +0000 2021</td>\n",
       "      <td>RT @covidbaseau: The TGA has approved the Mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed Dec 08 04:26:06 +0000 2021</td>\n",
       "      <td>RT @SimoLove: Federal Health Minister Greg Hun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed Dec 08 04:26:07 +0000 2021</td>\n",
       "      <td>@twityouse Are these the deniers that are wear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed Dec 08 04:26:07 +0000 2021</td>\n",
       "      <td>RT @drsimonegold: WOW: a preprint study for Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wed Dec 08 04:29:40 +0000 2021</td>\n",
       "      <td>RT @SimoLove: On Novak Djokovic, Federal Healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Wed Dec 08 04:29:51 +0000 2021</td>\n",
       "      <td>RT @GemmaTognini: Their son who lived in WA to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wed Dec 08 04:29:48 +0000 2021</td>\n",
       "      <td>RT @TheEconomist: Just one month ago, South Af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wed Dec 08 04:29:52 +0000 2021</td>\n",
       "      <td>RT @zerohedge: Vietnam Province Suspends Pfize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Wed Dec 08 04:29:51 +0000 2021</td>\n",
       "      <td>Neil Young Says He and Daryl Hannah Enjoyed 'J...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        created_at  \\\n",
       "0   Wed Dec 08 04:25:46 +0000 2021   \n",
       "1   Wed Dec 08 04:25:57 +0000 2021   \n",
       "2   Wed Dec 08 04:26:06 +0000 2021   \n",
       "3   Wed Dec 08 04:26:07 +0000 2021   \n",
       "4   Wed Dec 08 04:26:07 +0000 2021   \n",
       "..                             ...   \n",
       "95  Wed Dec 08 04:29:40 +0000 2021   \n",
       "96  Wed Dec 08 04:29:51 +0000 2021   \n",
       "97  Wed Dec 08 04:29:48 +0000 2021   \n",
       "98  Wed Dec 08 04:29:52 +0000 2021   \n",
       "99  Wed Dec 08 04:29:51 +0000 2021   \n",
       "\n",
       "                                                 text  \n",
       "0   RT @AaronSiriSG: Litigation update:  \\n\\nFDA d...  \n",
       "1   RT @covidbaseau: The TGA has approved the Mode...  \n",
       "2   RT @SimoLove: Federal Health Minister Greg Hun...  \n",
       "3   @twityouse Are these the deniers that are wear...  \n",
       "4   RT @drsimonegold: WOW: a preprint study for Th...  \n",
       "..                                                ...  \n",
       "95  RT @SimoLove: On Novak Djokovic, Federal Healt...  \n",
       "96  RT @GemmaTognini: Their son who lived in WA to...  \n",
       "97  RT @TheEconomist: Just one month ago, South Af...  \n",
       "98  RT @zerohedge: Vietnam Province Suspends Pfize...  \n",
       "99  Neil Young Says He and Daryl Hannah Enjoyed 'J...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa8228c-ce43-4f2b-ac95-4ed9608ce9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term: china, Count: 1\n",
      "17    China’s #yuan advanced to the strongest level ...\n",
      "Name: text, dtype: object\n",
      "Term: chinese, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: sinophobia, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: sinophobic, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: prc, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: wuhan, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: hubei, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: beijing, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: kung flu, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: chn, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: cn, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: ccp, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: yellow peril, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: chink, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: chinks, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: chingchong, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: ching chong, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: gook, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: chyna, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: mainland, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: mainlander, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: bugland, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: chines, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: mainla, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: chinazi, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: bugmen, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: chankoro, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: insectoid, Count: 0\n",
      "Series([], Name: text, dtype: object)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Dec 08 04:26:39 +0000 2021</td>\n",
       "      <td>China’s #yuan advanced to the strongest level ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Wed Dec 08 04:26:39 +0000 2021   \n",
       "\n",
       "                                                text  \n",
       "0  China’s #yuan advanced to the strongest level ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to hold DataFrames\n",
    "dfs_to_concat = []\n",
    "\n",
    "# List of sinophobic terms\n",
    "sinophobic_terms = ['china', 'chinese', 'sinophobia','sinophobic', 'prc', 'wuhan', 'hubei', 'beijing', 'kung flu', 'chn','cn', 'ccp', 'yellow peril', 'chink', 'chinks', \n",
    "                    'chingchong', 'ching chong', 'gook', 'chyna', 'mainland', 'mainlander', 'bugland', 'chines', \n",
    "                    'mainla', 'chinazi', 'bugmen', 'chankoro', 'insectoid']\n",
    "\n",
    "for term in sinophobic_terms:\n",
    "    filtered_df = df[df['text'].str.contains(f'\\\\b{term}\\\\b', case=False, na=False, regex=True)]\n",
    "    print(f\"Term: {term}, Count: {len(filtered_df)}\")\n",
    "    print(filtered_df['text'].head(5))  # Print the first 5 rows to inspect the content\n",
    "    dfs_to_concat.append(filtered_df)\n",
    "\n",
    "\n",
    "# Concatenate all filtered DataFrames\n",
    "final = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "\n",
    "# Remove duplicate entries\n",
    "final = final.drop_duplicates(subset=['text'])\n",
    "\n",
    "# Reset the index of the final DataFrame\n",
    "final = final.reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the final DataFrame\n",
    "final.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dfd0cf8-06a6-437e-9810-ce2016a2942c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95b03b69-19eb-41cf-b7a1-6ca302b7aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"BrAfterFilter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e46469b0-f32c-4d6b-a027-a25bfe7a88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withtime = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d98f4861-8d48-43d1-8555-ede1f760479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.drop(columns=['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2977662-2ba3-46c4-a80e-302be4ba1843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China’s #yuan advanced to the strongest level ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  China’s #yuan advanced to the strongest level ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07ba9215",
   "metadata": {
    "id": "07ba9215"
   },
   "outputs": [],
   "source": [
    "contractionsWithAnotherInvertedComma = {\n",
    "\"ain’t\": \"am not\", \"aren’t\": \"are not\", \"can’t\": \"cannot\", \"can’t’ve\": \"cannot have\", \"’cause\": \"because\", \"could’ve\": \"could have\", \"couldn’t\": \"could not\",\n",
    "\"couldn’t’ve\": \"could not have\", \"didn’t\": \"did not\", \"doesn’t\": \"does not\", \"don’t\": \"do not\", \"hadn’t\": \"had not\", \"hadn’t’ve\": \"had not have\",\n",
    "\"hasn’t\": \"has not\", \"haven’t\": \"have not\", \"he’d\": \"he had\", \"he’d’ve\": \"he would have\", \"he’ll\": \"he will\", \"he’ll’ve\": \"he will have\", \"he’s\": \"he is\",\n",
    "\"how’d\": \"how did\", \"how’d’y\": \"how do you\", \"how’ll\": \"how will\", \"how’s\": \"how is\", \"i’d\": \"i would\", \"i’d’ve\": \"i would have\",\n",
    "\"i’ll\": \"i will\", \"i’ll’ve\": \"i will have\", \"i’m\": \"i am\", \"i’ve\": \"i have\", \"isn’t\": \"is not\", \"it’d\": \"it would\",\n",
    "\"it’d’ve\": \"it would have\", \"it’ll\": \"it will\", \"it’ll’ve\": \"it will have\", \"it’s\": \"it is\", \"let’s\": \"let us\",\n",
    "\"ma’am\": \"madam\", \"mayn’t\": \"may not\", \"might’ve\": \"might have\", \"mightn’t\": \"might not\", \"mightn’t’ve\": \"might not have\", \"must’ve\": \"must have\", \"mustn’t\": \"must not\",\n",
    "\"mustn’t’ve\": \"must not have\", \"needn’t\": \"need not\", \"needn’t’ve\": \"need not have\", \"o’clock\": \"of the clock\", \"oughtn’t\": \"ought not\", \"oughtn’t’ve\": \"ought not have\",\n",
    "\"shan’t\": \"shall not\", \"shan’t’ve\": \"shall not have\", \"she’d\": \"she would\", \"she’d’ve\": \"she would have\", \"she’ll\": \"she will\",\n",
    "\"she’ll’ve\": \"she will have\", \"she’s\": \"she is\", \"should’ve\": \"should have\", \"shouldn’t\": \"should not\", \"shouldn’t’ve\": \"should not have\",\n",
    "\"so’ve\": \"so have\", \"so’s\": \"so is\", \"that’d\": \"that would\", \"that’d’ve\": \"that would have\", \"that’s\": \"that is\", \"there’d\": \"there would\",\n",
    "\"there’d’ve\": \"there would have\", \"there’s\": \"there is\", \"they’d\": \"they would\", \"they’d’ve\": \"they would have\", \"they’ll\": \"they will\",\n",
    "\"they’ll’ve\": \"they will have\", \"they’re\": \"they are\", \"they’ve\": \"they have\", \"to’ve\": \"to have\", \"wasn’t\": \"was not\", \"we’d\": \"we would\",\n",
    "\"we’d’ve\": \"we would have\", \"we’ll\": \"we will\", \"we’ll’ve\": \"we will have\", \"we’re\": \"we are\", \"we’ve\": \"we have\", \"weren’t\": \"were not\", \"what’ll\": \"what will\",\n",
    "\"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\",\n",
    "\"when’ve\": \"when have\", \"where’d\": \"where did\", \"where’s\": \"where is\", \"where’ve\": \"where have\", \"who’ll\": \"who will\", \"who’ll’ve\": \"who will have\",\n",
    "\"who’s\": \"who is\", \"who’ve\": \"who have\", \"why’s\": \"why is\", \"why’ve\": \"why have\", \"will’ve\": \"will have\", \"won’t\": \"will not\", \"won’t’ve\": \"will not have\",\n",
    "\"would’ve\": \"would have\", \"wouldn’t\": \"would not\", \"wouldn’t’ve\": \"would not have\", \"y’all\": \"you all\", \"y’all’d\": \"you all would\", \"y’all’d’ve\": \"you all would have\",\n",
    "\"y’all’re\": \"you all are\", \"y’all’ve\": \"you all have\", \"you’d\": \"you would\", \"you’d’ve\": \"you would have\", \"you’ll\": \"you will\", \"you’ll’ve\": \"you will have\",\n",
    "\"you’re\": \"you are\", \"you’ve\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90b36cc9",
   "metadata": {
    "id": "90b36cc9"
   },
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he had\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \"he'll've\": \"he will have\", \"he's\": \"he is\",\n",
    "\"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\", \"i'll've\": \"i will have\", \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"it's\": \"it is\", \"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\", \"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\", \"so's\": \"so is\", \"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\", \"there's\": \"there is\", \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\",\n",
    "\"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\", \"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\", \"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\", \"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b24df387-a3f6-4292-aa6c-047e978329ac",
   "metadata": {
    "id": "b24df387-a3f6-4292-aa6c-047e978329ac"
   },
   "outputs": [],
   "source": [
    "abbreviations_dict = {\n",
    "    \"ccp\": \"chinese communist party\", \"cn\": \"china\", \"chn\": \"china\", \"prc\": \"peoples republic of china\",\n",
    "    \"btw\": \"by the way\", \"brb\": \"be right back\",\n",
    "    \"b4n\": \"bye for now\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"ilu\": \"i love you\",\n",
    "    \"iow\": \"in other words\",\n",
    "    \"roflol\": \"rolling on the floor laughing out loud\",\n",
    "    \"rotflmao\": \"rolling on the floor laughing my ass off\",\n",
    "    \"fb\": \"facebook\", \"ig\": \"instagram\", \"li\": \"linkedin\", \"yt\": \"youtube\", \"tw\": \"twitter\",\n",
    "    \"dm\": \"direct message\", \"mt\": \"modified tweet\", \"pm\": \"private message\", \"rt\": \"retweet\",\n",
    "    \"b2b\": \"business to business\", \"b2c\": \"business to consumer\", \"cmgr\": \"community manager\",\n",
    "    \"cms\": \"content management system\", \"cpc\": \"cost per click\", \"cpm\": \"cost per thousand impressions\",\n",
    "    \"cr\": \"conversion rate\", \"cro\": \"conversion rate optimization\", \"cta\": \"call to action\",\n",
    "    \"ctr\": \"click-through rate\", \"roi\": \"return on investment\", \"smb\": \"small and midsize businesses\",\n",
    "    \"smp\": \"social media platform\", \"smm\": \"social media marketing\", \"smo\": \"social media optimization\",\n",
    "    \"solomo\": \"social, local and mobile\", \"srp\": \"social relationship platform\", \"tos\": \"terms of service\",\n",
    "    \"ugc\": \"user-generated content\", \"api\": \"application programming interface\", \"cx\": \"customer experience\",\n",
    "    \"esp\": \"email service provider\", \"ga\": \"google analytics\", \"isp\": \"internet service provider\",\n",
    "    \"pv\": \"page views\", \"rss\": \"really simple syndication\", \"saas\": \"software as a service\",\n",
    "    \"sem\": \"search engine marketing\", \"seo\": \"search engine optimization\", \"sov\": \"share of voice\",\n",
    "    \"ui\": \"user interface\", \"url\": \"uniform resource locator\", \"uv\": \"unique views\", \"ux\": \"user experience\",\n",
    "    \"afaik\": \"as far as i know\", \"ama\": \"ask me anything\", \"btaim\": \"be that as it may\",\n",
    "    \"bts\": \"behind the scenes\", \"dae\": \"does anyone else\", \"dyk\": \"did you know\",\n",
    "    \"eli5\": \"explain like i’m five\", \"fbf\": \"flashback friday\", \"fbo\": \"facebook official\",\n",
    "    \"ff\": \"follow friday\", \"fomo\": \"fear of missing out\", \"ftfy\": \"fixed that for you\",\n",
    "    \"ftw\": \"for the win\", \"g2g\": \"got to go\", \"gg\": \"good game\", \"gtr\": \"got to run\",\n",
    "    \"hbd\": \"happy birthday\", \"hifw\": \"how i feel when\", \"hmb\": \"hit me back\", \"hmu\": \"hit me up\",\n",
    "    \"ht\": \"hat tip\", \"h/t\": \"hat tip\", \"hth\": \"here to help\", \"icymi\": \"in case you missed it\",\n",
    "    \"idc\": \"i don’t care\", \"idk\": \"i don’t know\", \"ikr\": \"i know, right?\", \"ily\": \"i love you\",\n",
    "    \"imho\": \"in my humble opinion\", \"imo\": \"in my opinion\", \"irl\": \"in real life\", \"jk\": \"just kidding\",\n",
    "    \"lmao\": \"laughing my ass off\", \"lmk\": \"let me know\", \"lms\": \"like my status\",\n",
    "    \"lol\": \"laughing out loud\", \"mcm\": \"man crush monday\", \"mfw\": \"my face when\",\n",
    "    \"mtfbwy\": \"may the force be with you\", \"nbd\": \"no big deal\", \"nm\": \"not much\",\n",
    "    \"nsfw\": \"not safe for work\", \"nvm\": \"never mind\", \"oh\": \"overheard\", \"omw\": \"on my way\",\n",
    "    \"ootd\": \"outfit of the day\", \"op\": \"original poster\", \"otp\": \"one true pairing\", \"ppl\": \"people\",\n",
    "    \"rofl\": \"rolling on the floor laughing\", \"roflmao\": \"rolling on the floor laughing my ass off\",\n",
    "    \"sfw\": \"safe for work\", \"smh\": \"shaking my head\", \"tbh\": \"to be honest\", \"tbbh\": \"to be brutally honest\",\n",
    "    \"tbt\": \"throwback thursday\", \"tfw\": \"that feeling when\", \"tgif\": \"thank god it’s friday\",\n",
    "    \"til\": \"today i learned\", \"tl;dr\": \"too long; didn’t read\", \"tmi\": \"too much information\",\n",
    "    \"wbu\": \"what about you?\", \"wbw\": \"way back wednesday\", \"wfh\": \"work from home\", \"yolo\": \"you only live once\",\n",
    "    \"afk\": \"away from keyboard\", \"asap\": \"as soon as possible\", \"atk\": \"at the keyboard\",\n",
    "    \"atm\": \"at the moment\", \"a3\": \"anytime, anywhere, anyplace\", \"bak\": \"back at keyboard\",\n",
    "    \"bbl\": \"be back later\", \"bbs\": \"be back soon\", \"bfn\": \"bye for now\", \"brt\": \"be right there\",\n",
    "    \"b4\": \"before\", \"cu\": \"see you\", \"cul8r\": \"see you later\", \"cya\": \"see you\", \"faq\": \"frequently asked questions\",\n",
    "    \"fc\": \"fingers crossed\", \"fwiw\": \"for what it's worth\", \"gal\": \"get a life\", \"gn\": \"good night\",\n",
    "    \"gmta\": \"great minds think alike\", \"gr8\": \"great!\", \"g9\": \"genius\", \"ic\": \"i see\", \"icq\": \"i seek you\",\n",
    "    \"kiss\": \"keep it simple, stupid\", \"ldr\": \"long distance relationship\", \"ltns\": \"long time no see\",\n",
    "    \"l8r\": \"later\", \"mte\": \"my thoughts exactly\", \"m8\": \"mate\", \"nrn\": \"no reply necessary\", \"oic\": \"oh i see\",\n",
    "    \"pita\": \"pain in the a..\", \"prt\": \"party\", \"prw\": \"parents are watching\", \"qpsa\": \"que pasa?\",\n",
    "    \"sk8\": \"skate\", \"stats\": \"your sex and age\", \"asl\": \"age, sex, location\", \"thx\": \"thank you\",\n",
    "    \"ttfn\": \"ta-ta for now!\", \"ttyl\": \"talk to you later\", \"u\": \"you\", \"u2\": \"you too\", \"u4e\": \"yours for ever\",\n",
    "    \"wb\": \"welcome back\", \"wtf\": \"what the f...\", \"wtg\": \"way to go!\", \"wuf\": \"where are you from?\",\n",
    "    \"w8\": \"wait...\", \"7k\": \"sick:-d laugher\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "256c9da9-0c0b-4423-8455-a700d9a5f5f2",
   "metadata": {
    "id": "256c9da9-0c0b-4423-8455-a700d9a5f5f2"
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "class preprocess():\n",
    "    def __init__(self, df, contractions, otherContractions):\n",
    "        self.df = df\n",
    "        self.contractions = contractions\n",
    "        self.otherContractions = otherContractions\n",
    "\n",
    "    def lower(self, tweet):\n",
    "        return tweet.lower()\n",
    "\n",
    "    def abbreviate(self, tweet):\n",
    "        tweet_tokens = tweet.split(' ')\n",
    "        for i, token in enumerate(tweet_tokens):\n",
    "            cleaned_token = re.sub('[^a-zA-Z0-9-_.]', '', token)\n",
    "            if cleaned_token.lower() in abbreviations_dict:\n",
    "                tweet_tokens[i] = abbreviations_dict[cleaned_token.lower()]\n",
    "        return ' '.join(tweet_tokens)\n",
    "\n",
    "    def expand(self, tweet):\n",
    "        for word in tweet.split():\n",
    "            if word in self.contractions.keys():\n",
    "                tweet = tweet.replace(word, self.contractions[word])\n",
    "            elif word in self.otherContractions.keys():\n",
    "                tweet = tweet.replace(word, self.otherContractions[word])\n",
    "        return tweet\n",
    "\n",
    "    def emoji2text(self, tweet):\n",
    "        emojis = demoji.findall(tweet)\n",
    "        new_tweet = []\n",
    "        for word in tweet.split():\n",
    "            if word in emojis.keys():\n",
    "                tweet = tweet.replace(word, emojis[word])\n",
    "                new_tweet.append(emojis[word])\n",
    "            wordmojis = demoji.findall(word)\n",
    "            for char in word:\n",
    "                if char in wordmojis.keys():\n",
    "                    tweet = tweet.replace(word, wordmojis[char])\n",
    "\n",
    "        return tweet\n",
    "\n",
    "    def remove_hashtags(self, tweet):\n",
    "        return re.sub(r'\\#w+', '', tweet)\n",
    "\n",
    "    def remove_mentions(self, tweet):\n",
    "        for word in tweet.split():\n",
    "            if word[0] == '@':\n",
    "                tweet = tweet.replace(word, '')\n",
    "        return tweet\n",
    "\n",
    "    def remove_punctuations(self, tweet):\n",
    "        punct = string.punctuation\n",
    "        trantab = str.maketrans(punct, len(punct)*' ')\n",
    "        return tweet.translate(trantab)\n",
    "\n",
    "    def remove_url(self, tweet):\n",
    "        return re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', tweet, flags = re.MULTILINE)\n",
    "\n",
    "    def preprocess_tweet(self, tweet):\n",
    "        tweet = self.lower(tweet)\n",
    "        tweet = self.abbreviate(tweet)\n",
    "        tweet = self.expand(tweet)\n",
    "        tweet = self.emoji2text(tweet)\n",
    "        tweet = self.remove_mentions(tweet)\n",
    "        tweet = self.remove_url(tweet)\n",
    "        tweet = self.remove_hashtags(tweet)\n",
    "        tweet = self.remove_punctuations(tweet)\n",
    "\n",
    "        return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a454bf6e-7d8d-4f1f-acd1-d978d56a207a",
   "metadata": {
    "id": "a454bf6e-7d8d-4f1f-acd1-d978d56a207a"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "pp_class = preprocess(final, contractions, contractionsWithAnotherInvertedComma)\n",
    "final['text'] = final['text'].apply(lambda x : pp_class.preprocess_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e6801b3-f9e0-4f27-ba15-0b4c1ba47135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bruteGen(tweet):\n",
    "    tweet = tweet.replace(\"indiavscorona\", \"india versus coronavirus\")\n",
    "    tweet = tweet.replace(\"outbreakindia\", \"outbreak india\")\n",
    "    tweet = tweet.replace(\"real”\", \"real\")\n",
    "    tweet = tweet.replace(\"mutra\", \"urine\")\n",
    "    tweet = tweet.replace(\"fakenews\", \"fake news\")\n",
    "    tweet = tweet.replace(\"“omg\", \"oh my god\")\n",
    "    tweet = tweet.replace(\"“damn\", \"damn\")\n",
    "    tweet = tweet.replace(\"god’s\", \"gods\")\n",
    "    tweet = tweet.replace(\"lockdownextension\", \"lockdown extension\")\n",
    "    tweet = tweet.replace(\"कोरोना\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"indiathanks\", \"india thanks\")\n",
    "    tweet = tweet.replace(\"coronacoronavirus\", \"coronavirus\")\n",
    "    tweet = tweet.replace('coronavirusinsa', \"coronavirus in south africa\")\n",
    "    tweet = tweet.replace('coronaviruscanada', 'coronavirus canada')\n",
    "    tweet = tweet.replace('coronavirusau', 'coronavirus australia')\n",
    "    tweet = tweet.replace('coronavirusaus', 'coronavirus australia')\n",
    "    tweet = tweet.replace('cuomoprimetime', 'new york governor prime time')\n",
    "    tweet = tweet.replace('letsfightcoronavirus', 'let us fight coronavirus')\n",
    "    tweet = tweet.replace(\"covid 19\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"covid19\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"covid\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"aprilfoolsday\", \"april fools day\")\n",
    "    tweet = tweet.replace(\"covid-19\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"stayathome\", \"stay at home\")\n",
    "    tweet = tweet.replace(\"“april\", \"april\")\n",
    "    tweet = tweet.replace(\"“i\", \"i\")\n",
    "    tweet = tweet.replace(\"aprilfools\", \"april fools\")\n",
    "    tweet = tweet.replace(\"coronavirusoutbreak\", \"coronavirus outbreak\")\n",
    "    tweet = tweet.replace(\"virus-19\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"fool’s\", \"fools\")\n",
    "    tweet = tweet.replace(\"what’s\", \"what is\")\n",
    "    tweet = tweet.replace(\"coronavirus”\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"fools”\", \"fools\")\n",
    "    tweet = tweet.replace(\"stayhome\", \"stay home\")\n",
    "    tweet = tweet.replace(\"quarantinelife\", \"quarantine life\")\n",
    "    tweet = tweet.replace(\"tablighijamaat\", \"muslims\")\n",
    "    tweet = tweet.replace(\"corona”\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"fauci\", \"physician\")\n",
    "    tweet = tweet.replace(\"april’s\", \"april\")\n",
    "    tweet = tweet.replace(\"pmkcallscurfewextension\", \"prime minister calls for curfew extension\")\n",
    "    tweet = tweet.replace(\"“virus\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"virus”\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"“corona\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"coronavirustruth\", \"coronavirus truth\")\n",
    "    tweet = tweet.replace(\"socialdistancing\", \"social distancing\")\n",
    "    tweet = tweet.replace(\"homestaysafe\", \"home stay safe\")\n",
    "    tweet = tweet.replace(\"“coronavirus\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"coronavirusupdate\", \"coronavirus update\")\n",
    "    tweet = tweet.replace(\"virusvirus\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"coronaviruspandemic\", \"coronavirus pandemic\")\n",
    "    tweet = tweet.replace(\"thelockdown\", \"the lockdown\")\n",
    "    tweet = tweet.replace(\"nizamuddin\", \"delhi\")\n",
    "    tweet = tweet.replace(\"trump’s\", \"donald trump\")\n",
    "    tweet = tweet.replace(\"“the\", \"the\")\n",
    "    tweet = tweet.replace(\"virus2019\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"indiafightscorona\", \"india fights coronavirus\")\n",
    "    tweet = tweet.replace(\"homesavelives\", \"home save lives\")\n",
    "    tweet = tweet.replace(\"everyone’s\", \"everyone\")\n",
    "    tweet = tweet.replace(\"coronariskforprisoners\", \"coronavirus risk for prisoners\")\n",
    "    tweet = tweet.replace(\"coronavirususa\", \"coronavirus usa\")\n",
    "    tweet = tweet.replace(\"tablighi\", \"mosque\")\n",
    "    tweet = tweet.replace(\"delhimarkaz\", \"delhi mosque\")\n",
    "    tweet = tweet.replace(\"coronajihad\", \"coronavirus struggle\")\n",
    "    tweet = tweet.replace(\"coronajihaad\", \"coronavirus struggle\")\n",
    "    tweet = tweet.replace(\"aprilfool\", \"april fool\")\n",
    "    tweet = tweet.replace(\"trumppressconference\", \"trump press conference\")\n",
    "    tweet = tweet.replace(\"i’m\", \"i am\")\n",
    "    tweet = tweet.replace(\"tigerking\", \"tiger king\")\n",
    "    tweet = tweet.replace(\"it’s\", \"it is\")\n",
    "    tweet = tweet.replace(\"trumpvirus\", \"trump virus\")\n",
    "    tweet = tweet.replace(\"today’s\", \"today is\")\n",
    "    tweet = tweet.replace(\"“you\", \"you\")\n",
    "    tweet = tweet.replace(\"“a\", \"a\")\n",
    "    tweet = tweet.replace(\"fools’\", \"fools\")\n",
    "    tweet = tweet.replace(\"rtgnews\", \"news\")\n",
    "    tweet = tweet.replace(\"19india\", \"india\")\n",
    "    tweet = tweet.replace(\"coronavirusindia\", \"coronavirus india\")\n",
    "    tweet = tweet.replace(\"y’all\", \"you all\")\n",
    "    tweet = tweet.replace(\"मीडिया\", \"media\")\n",
    "    tweet = tweet.replace(\"here’s\", \"here is\")\n",
    "    tweet = tweet.replace(\"“we\", \"we\")\n",
    "    tweet = tweet.replace(\"“fuck\", \"fuck\")\n",
    "    tweet = tweet.replace(\"flattenthecurve\", \"flatten the curve\")\n",
    "    tweet = tweet.replace(\"jammuandkashmir\", \"jammu and kashmir\")\n",
    "    tweet = tweet.replace(\"chriscuomo\", \"new york governor\")\n",
    "    tweet = tweet.replace(\"‘april\", \"april\")\n",
    "    tweet = tweet.replace(\"dranbumani\", \"doctor\")\n",
    "    tweet = tweet.replace(\"tndemandsmasstesting\", \"tamil nadu demands mass testing\")\n",
    "    tweet = tweet.replace(\"tabligi\", \"muslims\")\n",
    "    tweet = tweet.replace(\"don’t\", \"do not\")\n",
    "    tweet = tweet.replace(\"वायरस\", \"virus\")\n",
    "    tweet = tweet.replace(\"letsfightvirus\", \"let us fight virus\")\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59841f87-b1be-40a5-a3d7-53d9d4ccae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final['text'] = final['text'].apply(lambda x : bruteGen(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad5973ce-2151-45fd-b658-4adc38e9ff9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "ad5973ce-2151-45fd-b658-4adc38e9ff9a",
    "outputId": "48eb9c18-e838-401a-cc37-d940255da3f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                 text\n",
       "0  china’s  yuan advanced to the strongest level ...>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2529f8c-88d9-453b-8e73-d0015f372b41",
   "metadata": {
    "id": "d2529f8c-88d9-453b-8e73-d0015f372b41"
   },
   "outputs": [],
   "source": [
    "labels = ['Optimistic', 'Thankful', 'Empathetic', 'Pessimistic',\n",
    "       'Anxious', 'Sad', 'Annoyed', 'Denial', 'Official report', 'Joking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4525733d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "4525733d",
    "outputId": "57db59d9-c373-407f-fe7e-f79bebbe5da4"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86a46e47",
   "metadata": {
    "id": "86a46e47"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Tweet'] = final['text']\n",
    "values = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] * len(final)\n",
    "df[labels] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02909eb7-8051-4503-9f5c-4ea28bc97b2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "02909eb7-8051-4503-9f5c-4ea28bc97b2e",
    "outputId": "da3cb534-5204-4470-c534-38acde5448b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Optimistic</th>\n",
       "      <th>Thankful</th>\n",
       "      <th>Empathetic</th>\n",
       "      <th>Pessimistic</th>\n",
       "      <th>Anxious</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Annoyed</th>\n",
       "      <th>Denial</th>\n",
       "      <th>Official report</th>\n",
       "      <th>Joking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>china’s  yuan advanced to the strongest level ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Optimistic  Thankful  \\\n",
       "0  china’s  yuan advanced to the strongest level ...           0         0   \n",
       "\n",
       "   Empathetic  Pessimistic  Anxious  Sad  Annoyed  Denial  Official report  \\\n",
       "0           0            0        0    0        0       0                0   \n",
       "\n",
       "   Joking  \n",
       "0       0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b4515b1-d9f8-4691-8a40-5219d9bcd8b2",
   "metadata": {
    "id": "1b4515b1-d9f8-4691-8a40-5219d9bcd8b2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "   def __init__(self,df,tokenizer,max_len):\n",
    "     self.df = df\n",
    "     self.tokenizer = tokenizer\n",
    "     self.max_len = max_len\n",
    "     self.title = self.df['Tweet']\n",
    "     self.targets = self.df[labels].values\n",
    "\n",
    "   def __len__(self):\n",
    "     return len(self.title)\n",
    "\n",
    "   def __getitem__(self,index):\n",
    "     title = str(self.title[index])\n",
    "     title = \" \".join(title.split())\n",
    "\n",
    "     inputs = self.tokenizer.encode_plus(\n",
    "         title,\n",
    "         None,\n",
    "         add_special_tokens=True,\n",
    "         max_length=self.max_len,\n",
    "         padding='max_length',\n",
    "         return_token_type_ids=True,\n",
    "         truncation=True,\n",
    "         return_attention_mask=True,\n",
    "         return_tensors='pt'\n",
    "     )\n",
    "     return {\n",
    "         'input_ids':inputs['input_ids'].flatten(),\n",
    "         'attention_mask':inputs['attention_mask'].flatten(),\n",
    "         'token_type_ids':inputs['token_type_ids'].flatten(),\n",
    "         'targets':torch.FloatTensor(self.targets[index])\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c63b8ddb-04c5-4357-98be-43d7f8c2aafa",
   "metadata": {
    "id": "c63b8ddb-04c5-4357-98be-43d7f8c2aafa"
   },
   "outputs": [],
   "source": [
    "MAX_LEN=256\n",
    "_dataset = CustomDataset(df, tokenizer, MAX_LEN)\n",
    "_data_loader = torch.utils.data.DataLoader(\n",
    "    _dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=8,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc1c4de2-18da-44c1-9dae-ffab21e5313b",
   "metadata": {
    "id": "bc1c4de2-18da-44c1-9dae-ffab21e5313b"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7df4df5f-9f7e-409f-beda-7546ab13d765",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 902,
     "referenced_widgets": [
      "98044adc3f554490bb622f6b98563760",
      "1f787c1c68e04f248dca364ff388e242",
      "c72188bc55604e83a3ee05c442356799",
      "ef54033832254f00bc94bba0e16d2e7b",
      "cd9d4fbf0f094d2a89a843ddf100427e",
      "505b3ca46d754dbbb0cfedbb0f7e1a95",
      "d2e686f21bf64b1f9c506763db900de3",
      "cd00f7fd0c784ea58654a0bb3f7a4e59",
      "2786ab14b0d548388f234ff30df73b95",
      "c50d3410574243ab8a909c30197eec4e",
      "649c639f49c84ddbb42399f0f1b9f4ae"
     ]
    },
    "id": "7df4df5f-9f7e-409f-beda-7546ab13d765",
    "outputId": "6be243aa-4846-44d0-d7f6-592d326e34f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (layer1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Dropout(p=0.3, inplace=False)\n",
       "  (layer3): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.layer2 = torch.nn.Dropout(0.3)\n",
    "        self.layer3 = torch.nn.Linear(768, 10)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids, return_dict = False):\n",
    "        unw, out_1 = self.layer1(ids, attention_mask = mask, token_type_ids = token_type_ids)[0], self.layer1(ids, attention_mask = mask, token_type_ids = token_type_ids)[1]\n",
    "        out_2 = self.layer2(out_1)\n",
    "        out_final = self.layer3(out_2)\n",
    "        return out_final\n",
    "\n",
    "\n",
    "model = BERT()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ZQbVtaIWAnlW",
   "metadata": {
    "id": "ZQbVtaIWAnlW"
   },
   "outputs": [],
   "source": [
    "model = torch.load(\"FinalBertModel.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9d4b235-d54d-4f86-8fab-720581f961d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d9d4b235-d54d-4f86-8fab-720581f961d2",
    "outputId": "a1c74c66-1838-4ad0-dcc2-a0fe3f613158"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "bert_outputs = []\n",
    "with torch.no_grad():\n",
    "\n",
    "  for index, batch in enumerate(_data_loader):\n",
    "         input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "         attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "         token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "         targets =  batch['targets'].to(device, dtype=torch.float)\n",
    "         outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "         bert_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc9c36a8-07de-449d-b0a0-efb553bceb3e",
   "metadata": {
    "id": "bc9c36a8-07de-449d-b0a0-efb553bceb3e"
   },
   "outputs": [],
   "source": [
    "test_outputs = np.array(bert_outputs)\n",
    "\n",
    "for i in range(test_outputs.shape[0]):\n",
    "    for j in range(test_outputs.shape[1]):\n",
    "        if test_outputs[i][j] >= 0.5: test_outputs[i][j] = 1\n",
    "        else: test_outputs[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6fa8563-7186-4523-b14c-87d60497540c",
   "metadata": {
    "id": "a6fa8563-7186-4523-b14c-87d60497540c"
   },
   "outputs": [],
   "source": [
    "df[labels] = test_outputs.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64259cdf-b77d-4161-b1d0-02c56fcc6dcc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "id": "64259cdf-b77d-4161-b1d0-02c56fcc6dcc",
    "outputId": "5540fcc4-a2d7-404c-8f34-90c763559477"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Optimistic</th>\n",
       "      <th>Thankful</th>\n",
       "      <th>Empathetic</th>\n",
       "      <th>Pessimistic</th>\n",
       "      <th>Anxious</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Annoyed</th>\n",
       "      <th>Denial</th>\n",
       "      <th>Official report</th>\n",
       "      <th>Joking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>china’s  yuan advanced to the strongest level ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Optimistic  Thankful  \\\n",
       "0  china’s  yuan advanced to the strongest level ...           0         0   \n",
       "\n",
       "   Empathetic  Pessimistic  Anxious  Sad  Annoyed  Denial  Official report  \\\n",
       "0           0            0        0    0        0       0                1   \n",
       "\n",
       "   Joking  \n",
       "0       0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e71e5f52-9a20-42a8-82cc-52977f77a6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Dec 08 04:26:39 +0000 2021</td>\n",
       "      <td>China’s #yuan advanced to the strongest level ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Wed Dec 08 04:26:39 +0000 2021   \n",
       "\n",
       "                                                text  \n",
       "0  China’s #yuan advanced to the strongest level ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_withtime.reset_index(drop=True, inplace=True)\n",
    "df_withtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdf76702-e80f-42cf-a09b-35415d2518c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>Optimistic</th>\n",
       "      <th>Thankful</th>\n",
       "      <th>Empathetic</th>\n",
       "      <th>Pessimistic</th>\n",
       "      <th>Anxious</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Annoyed</th>\n",
       "      <th>Denial</th>\n",
       "      <th>Official report</th>\n",
       "      <th>Joking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>china’s  yuan advanced to the strongest level ...</td>\n",
       "      <td>China’s #yuan advanced to the strongest level ...</td>\n",
       "      <td>Wed Dec 08 04:26:39 +0000 2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  china’s  yuan advanced to the strongest level ...   \n",
       "\n",
       "                                                text  \\\n",
       "0  China’s #yuan advanced to the strongest level ...   \n",
       "\n",
       "                             date  Optimistic  Thankful  Empathetic  \\\n",
       "0  Wed Dec 08 04:26:39 +0000 2021           0         0           0   \n",
       "\n",
       "   Pessimistic  Anxious  Sad  Annoyed  Denial  Official report  Joking  \n",
       "0            0        0    0        0       0                1       0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aus = pd.DataFrame()\n",
    "Aus['Tweet'] = df['Tweet']\n",
    "Aus['text'] = df_withtime['text']\n",
    "Aus['date'] = df_withtime['created_at']\n",
    "Aus[labels] = df[labels]\n",
    "Aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c481d926-bbcc-4a26-89cc-3a96e6896ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aus.to_csv(\"ResultAus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cff1ec-394c-4c3b-a713-9e08dcbd3539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1f787c1c68e04f248dca364ff388e242": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_505b3ca46d754dbbb0cfedbb0f7e1a95",
      "placeholder": "​",
      "style": "IPY_MODEL_d2e686f21bf64b1f9c506763db900de3",
      "value": "Downloading: 100%"
     }
    },
    "2786ab14b0d548388f234ff30df73b95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "505b3ca46d754dbbb0cfedbb0f7e1a95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "649c639f49c84ddbb42399f0f1b9f4ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98044adc3f554490bb622f6b98563760": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f787c1c68e04f248dca364ff388e242",
       "IPY_MODEL_c72188bc55604e83a3ee05c442356799",
       "IPY_MODEL_ef54033832254f00bc94bba0e16d2e7b"
      ],
      "layout": "IPY_MODEL_cd9d4fbf0f094d2a89a843ddf100427e"
     }
    },
    "c50d3410574243ab8a909c30197eec4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c72188bc55604e83a3ee05c442356799": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd00f7fd0c784ea58654a0bb3f7a4e59",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2786ab14b0d548388f234ff30df73b95",
      "value": 440473133
     }
    },
    "cd00f7fd0c784ea58654a0bb3f7a4e59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd9d4fbf0f094d2a89a843ddf100427e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2e686f21bf64b1f9c506763db900de3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef54033832254f00bc94bba0e16d2e7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c50d3410574243ab8a909c30197eec4e",
      "placeholder": "​",
      "style": "IPY_MODEL_649c639f49c84ddbb42399f0f1b9f4ae",
      "value": " 420M/420M [00:07&lt;00:00, 70.0MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
