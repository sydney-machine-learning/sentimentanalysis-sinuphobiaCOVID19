{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6mcZK_I-_OXK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mcZK_I-_OXK",
    "outputId": "142085ab-4b37-4c48-cc1c-3813629433d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.10.0\n",
      "  Using cached transformers-4.10.0-py3-none-any.whl.metadata (51 kB)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (1.24.4)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (2023.12.25)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (2.32.3)\n",
      "Requirement already satisfied: sacremoses in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (0.1.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1 (from transformers==4.10.0)\n",
      "  Using cached tokenizers-0.10.3-cp39-cp39-win_amd64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from transformers==4.10.0) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from huggingface-hub>=0.0.12->transformers==4.10.0) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from huggingface-hub>=0.0.12->transformers==4.10.0) (4.10.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\py39\\lib\\site-packages (from tqdm>=4.27->transformers==4.10.0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from requests->transformers==4.10.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from requests->transformers==4.10.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from requests->transformers==4.10.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\py39\\lib\\site-packages (from requests->transformers==4.10.0) (2024.2.2)\n",
      "Requirement already satisfied: click in d:\\anaconda\\envs\\py39\\lib\\site-packages (from sacremoses->transformers==4.10.0) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\envs\\py39\\lib\\site-packages (from sacremoses->transformers==4.10.0) (1.3.2)\n",
      "Using cached transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
      "Using cached tokenizers-0.10.3-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.41.2\n",
      "    Uninstalling transformers-4.41.2:\n",
      "      Successfully uninstalled transformers-4.41.2\n",
      "Successfully installed tokenizers-0.10.3 transformers-4.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\Anaconda\\envs\\py39\\Lib\\site-packages\\~.kenizers'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 3.0.0 requires transformers<5.0.0,>=4.34.0, but you have transformers 4.10.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2cd9a0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "NMK4CvTko7Dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NMK4CvTko7Dd",
    "outputId": "4332d180-f5fb-4a59-98d5-03f575bb53bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.10.0\n",
      "Summary: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Sam Shleifer, Patrick von Platen, Sylvain Gugger, Suraj Patil, Stas Bekman, Google AI Language Team Authors, Open AI team Authors, Facebook AI Authors, Carnegie Mellon University Authors\n",
      "Author-email: thomas@huggingface.co\n",
      "License: Apache\n",
      "Location: d:\\anaconda\\envs\\py39\\lib\\site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, sacremoses, tokenizers, tqdm\n",
      "Required-by: sentence-transformers\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7aa1a2-4ba4-4a43-8aab-bd1ad3beab7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af7aa1a2-4ba4-4a43-8aab-bd1ad3beab7a",
    "outputId": "dca5a64e-2a21-43f7-c5de-dc1cfc7b3851"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import demoji\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"D:\\\\Sinophobia Sentiment Analysis\\\\archive\\\\Tweets_Indonesia\\\\Tweets_Indonesia.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc599e4-f3a5-4de7-bea0-0cfdfb0f1c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>542</td>\n",
       "      <td>Wed Dec 08 04:26:24 +0000 2021</td>\n",
       "      <td>1468436777123807233</td>\n",
       "      <td>@cryptocclub01 @DeepBrainChain COVID 19 has sl...</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1910</td>\n",
       "      <td>Wed Dec 08 04:28:11 +0000 2021</td>\n",
       "      <td>1468437225574526981</td>\n",
       "      <td>RT @baemyooji: aespa received '2021 Visionary ...</td>\n",
       "      <td>Kota Batam, Kepulauan Riau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>Wed Dec 08 04:28:28 +0000 2021</td>\n",
       "      <td>1468437299008442368</td>\n",
       "      <td>RT @FaheemYounus: Omicron does not spread thro...</td>\n",
       "      <td>Bekasi, Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2586</td>\n",
       "      <td>Wed Dec 08 04:29:10 +0000 2021</td>\n",
       "      <td>1468437474003206144</td>\n",
       "      <td>Hopefully im win..still believe @ElrondNetwork...</td>\n",
       "      <td>Bogor Barat, Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2743</td>\n",
       "      <td>Wed Dec 08 04:29:24 +0000 2021</td>\n",
       "      <td>1468437531515568131</td>\n",
       "      <td>RT @michaelmina_lab: I can’t believe this isn’...</td>\n",
       "      <td>into an alternate reality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229930</th>\n",
       "      <td>90384</td>\n",
       "      <td>Fri Aug 21 22:50:19 +0000 2020</td>\n",
       "      <td>1296942738546536449</td>\n",
       "      <td>RT @AidaGreenbury: The silent suffering of Ind...</td>\n",
       "      <td>London, Norfolk, Bali, Borneo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229931</th>\n",
       "      <td>90448</td>\n",
       "      <td>Fri Aug 21 22:50:23 +0000 2020</td>\n",
       "      <td>1296942756414144513</td>\n",
       "      <td>RT @9GAG: Type \"during quarantine, I learned h...</td>\n",
       "      <td>Jakarta Selatan, DKI Jakarta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229932</th>\n",
       "      <td>90674</td>\n",
       "      <td>Fri Aug 21 22:50:34 +0000 2020</td>\n",
       "      <td>1296942799258968065</td>\n",
       "      <td>RT @NASASun: Three years ago today, millions o...</td>\n",
       "      <td>Malang, Jawa Timur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229933</th>\n",
       "      <td>90677</td>\n",
       "      <td>Fri Aug 21 22:50:31 +0000 2020</td>\n",
       "      <td>1296942790396452864</td>\n",
       "      <td>RT @lenoretaylor: Why did we expect aged care ...</td>\n",
       "      <td>Bali, Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229934</th>\n",
       "      <td>90966</td>\n",
       "      <td>Fri Aug 21 22:50:43 +0000 2020</td>\n",
       "      <td>1296942840702853120</td>\n",
       "      <td>You have to add Indonesia with USA https://t.c...</td>\n",
       "      <td>Jakarta.  Bali</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229935 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                      created_at                   id  \\\n",
       "0             542  Wed Dec 08 04:26:24 +0000 2021  1468436777123807233   \n",
       "1            1910  Wed Dec 08 04:28:11 +0000 2021  1468437225574526981   \n",
       "2            2018  Wed Dec 08 04:28:28 +0000 2021  1468437299008442368   \n",
       "3            2586  Wed Dec 08 04:29:10 +0000 2021  1468437474003206144   \n",
       "4            2743  Wed Dec 08 04:29:24 +0000 2021  1468437531515568131   \n",
       "...           ...                             ...                  ...   \n",
       "229930      90384  Fri Aug 21 22:50:19 +0000 2020  1296942738546536449   \n",
       "229931      90448  Fri Aug 21 22:50:23 +0000 2020  1296942756414144513   \n",
       "229932      90674  Fri Aug 21 22:50:34 +0000 2020  1296942799258968065   \n",
       "229933      90677  Fri Aug 21 22:50:31 +0000 2020  1296942790396452864   \n",
       "229934      90966  Fri Aug 21 22:50:43 +0000 2020  1296942840702853120   \n",
       "\n",
       "                                                     text  \\\n",
       "0       @cryptocclub01 @DeepBrainChain COVID 19 has sl...   \n",
       "1       RT @baemyooji: aespa received '2021 Visionary ...   \n",
       "2       RT @FaheemYounus: Omicron does not spread thro...   \n",
       "3       Hopefully im win..still believe @ElrondNetwork...   \n",
       "4       RT @michaelmina_lab: I can’t believe this isn’...   \n",
       "...                                                   ...   \n",
       "229930  RT @AidaGreenbury: The silent suffering of Ind...   \n",
       "229931  RT @9GAG: Type \"during quarantine, I learned h...   \n",
       "229932  RT @NASASun: Three years ago today, millions o...   \n",
       "229933  RT @lenoretaylor: Why did we expect aged care ...   \n",
       "229934  You have to add Indonesia with USA https://t.c...   \n",
       "\n",
       "                        user_location  \n",
       "0                           Indonesia  \n",
       "1          Kota Batam, Kepulauan Riau  \n",
       "2                   Bekasi, Indonesia  \n",
       "3              Bogor Barat, Indonesia  \n",
       "4           into an alternate reality  \n",
       "...                               ...  \n",
       "229930  London, Norfolk, Bali, Borneo  \n",
       "229931   Jakarta Selatan, DKI Jakarta  \n",
       "229932             Malang, Jawa Timur  \n",
       "229933                Bali, Indonesia  \n",
       "229934                 Jakarta.  Bali  \n",
       "\n",
       "[229935 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "448f1759",
   "metadata": {
    "id": "448f1759"
   },
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "df = df.drop(columns=['Unnamed: 0', 'id', 'user_location'])\n",
    "\n",
    "df = df.dropna(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "072a4554-69a2-44a8-8227-0f3fd5d40769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Dec 08 04:26:24 +0000 2021</td>\n",
       "      <td>@cryptocclub01 @DeepBrainChain COVID 19 has sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed Dec 08 04:28:11 +0000 2021</td>\n",
       "      <td>RT @baemyooji: aespa received '2021 Visionary ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed Dec 08 04:28:28 +0000 2021</td>\n",
       "      <td>RT @FaheemYounus: Omicron does not spread thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed Dec 08 04:29:10 +0000 2021</td>\n",
       "      <td>Hopefully im win..still believe @ElrondNetwork...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed Dec 08 04:29:24 +0000 2021</td>\n",
       "      <td>RT @michaelmina_lab: I can’t believe this isn’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229930</th>\n",
       "      <td>Fri Aug 21 22:50:19 +0000 2020</td>\n",
       "      <td>RT @AidaGreenbury: The silent suffering of Ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229931</th>\n",
       "      <td>Fri Aug 21 22:50:23 +0000 2020</td>\n",
       "      <td>RT @9GAG: Type \"during quarantine, I learned h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229932</th>\n",
       "      <td>Fri Aug 21 22:50:34 +0000 2020</td>\n",
       "      <td>RT @NASASun: Three years ago today, millions o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229933</th>\n",
       "      <td>Fri Aug 21 22:50:31 +0000 2020</td>\n",
       "      <td>RT @lenoretaylor: Why did we expect aged care ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229934</th>\n",
       "      <td>Fri Aug 21 22:50:43 +0000 2020</td>\n",
       "      <td>You have to add Indonesia with USA https://t.c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229932 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            created_at  \\\n",
       "0       Wed Dec 08 04:26:24 +0000 2021   \n",
       "1       Wed Dec 08 04:28:11 +0000 2021   \n",
       "2       Wed Dec 08 04:28:28 +0000 2021   \n",
       "3       Wed Dec 08 04:29:10 +0000 2021   \n",
       "4       Wed Dec 08 04:29:24 +0000 2021   \n",
       "...                                ...   \n",
       "229930  Fri Aug 21 22:50:19 +0000 2020   \n",
       "229931  Fri Aug 21 22:50:23 +0000 2020   \n",
       "229932  Fri Aug 21 22:50:34 +0000 2020   \n",
       "229933  Fri Aug 21 22:50:31 +0000 2020   \n",
       "229934  Fri Aug 21 22:50:43 +0000 2020   \n",
       "\n",
       "                                                     text  \n",
       "0       @cryptocclub01 @DeepBrainChain COVID 19 has sl...  \n",
       "1       RT @baemyooji: aespa received '2021 Visionary ...  \n",
       "2       RT @FaheemYounus: Omicron does not spread thro...  \n",
       "3       Hopefully im win..still believe @ElrondNetwork...  \n",
       "4       RT @michaelmina_lab: I can’t believe this isn’...  \n",
       "...                                                   ...  \n",
       "229930  RT @AidaGreenbury: The silent suffering of Ind...  \n",
       "229931  RT @9GAG: Type \"during quarantine, I learned h...  \n",
       "229932  RT @NASASun: Three years ago today, millions o...  \n",
       "229933  RT @lenoretaylor: Why did we expect aged care ...  \n",
       "229934  You have to add Indonesia with USA https://t.c...  \n",
       "\n",
       "[229932 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c594fc38-0f19-4c47-ac17-f30457907e3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "c594fc38-0f19-4c47-ac17-f30457907e3a",
    "outputId": "0c1b7126-b825-48d9-8a46-a3cc3853f010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term: china, Count: 1946\n",
      "47     RT @songpinganq: @Ev1HasAnOpinion @imajollyrog...\n",
      "182    @jacobqvirin @bwfmedia please jacob that is th...\n",
      "279    The United States and Australia will send athl...\n",
      "294    RT @MicrobesInfo: #Bird #Flu #outbreak in #Chi...\n",
      "678    @irvinethesteve I live here) \\nCame from China...\n",
      "Name: text, dtype: object\n",
      "Term: chinese, Count: 1011\n",
      "613     RT @Echinanews: Nearly 2.57 billion doses of C...\n",
      "1108    RT @patcondell: Vaccine passports were the pla...\n",
      "1317    RT @patcondell: Vaccine passports were the pla...\n",
      "1441    St. Mary's cult.\\nThat's the real origin and t...\n",
      "3092    @gochisox1609 @luvwhiskey_wine Yeah you got th...\n",
      "Name: text, dtype: object\n",
      "Term: sinophobia, Count: 2\n",
      "91752     45 brought sinophobia to the states with his h...\n",
      "160847    What started of as valid evidence-based critic...\n",
      "Name: text, dtype: object\n",
      "Term: sinophobic, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: prc, Count: 6\n",
      "17276     RT @WeeeklyFD: All members are fine according ...\n",
      "39157     Hi 👋 ASEAN family\\n\\n#NewsFromPhilippines🇵🇭\\n\\...\n",
      "106147    RT @FBI: U.S. researchers studying #COVID19 mu...\n",
      "192748    RT @CollinSLKoh: Some impending development to...\n",
      "192749    RT @CollinSLKoh: Some impending development to...\n",
      "Name: text, dtype: object\n",
      "Term: wuhan, Count: 429\n",
      "3168    RT @Katy30770035: REMINDER: Peter Daszak descr...\n",
      "3600    RT @StephenMcDonell: Two years ago this happen...\n",
      "3614    RT @StephenMcDonell: Two years ago this happen...\n",
      "4527    RT @StephenMcDonell: Two years ago this happen...\n",
      "4731    RT @StephenMcDonell: Two years ago this happen...\n",
      "Name: text, dtype: object\n",
      "Term: hubei, Count: 16\n",
      "46479     China PCR Test Orders SOARED Before First Conf...\n",
      "68828     RT @quay_dr: But Dr. Shi said in July 2020 tha...\n",
      "133689    RT @SpokespersonCHN: As we will soon meet in L...\n",
      "133702    RT @XHNews: Feel the speed of Hubei in 60 seco...\n",
      "134362    A Hubei Reborn for New Glories; \\nA China Embr...\n",
      "Name: text, dtype: object\n",
      "Term: beijing, Count: 95\n",
      "279      The United States and Australia will send athl...\n",
      "285      RT @nuicemedia: The United States and Australi...\n",
      "530      RT @nuicemedia: The United States and Australi...\n",
      "12742    RT @menjunfei: he had prepared a lot in beijin...\n",
      "14343    RT @people: Mikaela Shiffrin Tests Positive fo...\n",
      "Name: text, dtype: object\n",
      "Term: kung flu, Count: 26\n",
      "8389     @WilliamNOtis @clockoutwars \"Most recently, Tr...\n",
      "8401     @WilliamNOtis @clockoutwars “kung flu” a “high...\n",
      "90910    RT @jennyyangtv: Asian women are your punchlin...\n",
      "90993    RT @tedlieu: The former President used racist ...\n",
      "91012    RT @tedlieu: The former President used racist ...\n",
      "Name: text, dtype: object\n",
      "Term: chn, Count: 18\n",
      "20994    RT @shitouyuqi: Signs of suspension in CHN whe...\n",
      "23569    RT @BTOBSupports: [UCUBE NOTICE] Information o...\n",
      "23600    RT @BTOBSupports: [UCUBE NOTICE] Information o...\n",
      "23685    RT @BTOBSupports: [UCUBE NOTICE] Information o...\n",
      "26414    RT @BTOBSupports: 211220 [UCUBE NOTICE] Inform...\n",
      "Name: text, dtype: object\n",
      "Term: cn, Count: 11\n",
      "35481     RT @JFortepiano: [ENG SUB] #JUN's Vlog EP.01\\n...\n",
      "63919     @JChildNeurol @DGlaucomflecken Only test CN 1 ...\n",
      "64676     @JChildNeurol @DGlaucomflecken Only test CN 1 ...\n",
      "99907     Arknights EN/JP/KR Players :\\n\\n❌❌❌ Thanking C...\n",
      "120102    RT @nanahoshiren: Please listen to this EP... ...\n",
      "Name: text, dtype: object\n",
      "Term: ccp, Count: 149\n",
      "926      RT @ClareMLopez: The truth about the #CCP-#PLA...\n",
      "3130     RT @galaxyalpha999: 🌟🌟🌟1/2/2022 Japan Alert: 5...\n",
      "4331     RT @KathMLee1: Wow. The CCP propaganda is some...\n",
      "8561     RT @DrLiMengYAN1: Thank you, @KenMac55! But th...\n",
      "13093    RT @DrLiMengYAN1: ‘She was inspired to speak u...\n",
      "Name: text, dtype: object\n",
      "Term: yellow peril, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: chink, Count: 1\n",
      "107220    @KooyJan @MSNBC @hrw @Yaqiu Because The Chink ...\n",
      "Name: text, dtype: object\n",
      "Term: chinks, Count: 2\n",
      "89243    I can see chinks of light at the end of my loc...\n",
      "92784    RT @christineahn: Wuhan virus and kungflu wasn...\n",
      "Name: text, dtype: object\n",
      "Term: chingchong, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: ching chong, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: gook, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: chyna, Count: 2\n",
      "26070     RT @1foreverseeking: Always about the money......\n",
      "178060    RT @1foreverseeking: Always about the money......\n",
      "Name: text, dtype: object\n",
      "Term: mainland, Count: 43\n",
      "613      RT @Echinanews: Nearly 2.57 billion doses of C...\n",
      "7340     Chinese mainland reports 37 locally transmitte...\n",
      "23610    Chinese mainland reports 56 locally transmitte...\n",
      "30066    It’s what health workers here expect. They’re ...\n",
      "37797    Doughnut day\\nHong Kong to reopen quarantine-f...\n",
      "Name: text, dtype: object\n",
      "Term: mainlander, Count: 2\n",
      "4646      @PAPHELAN @MonteBovill I'm a mainlander so all...\n",
      "128969    &gt; double vaccinated Mainlander getting covi...\n",
      "Name: text, dtype: object\n",
      "Term: bugland, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: chines, Count: 3\n",
      "67418     RT @60Minutes: U.S. officials say the Chinese ...\n",
      "192174    RT @AFP: VIDEO:  Wuhan clubbers party all nigh...\n",
      "192189    RT @AFP: VIDEO:  Wuhan clubbers party all nigh...\n",
      "Name: text, dtype: object\n",
      "Term: mainla, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: chinazi, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: bugmen, Count: 1\n",
      "115235    i take it back when i say the entire indie gam...\n",
      "Name: text, dtype: object\n",
      "Term: chankoro, Count: 0\n",
      "Series([], Name: text, dtype: object)\n",
      "Term: insectoid, Count: 0\n",
      "Series([], Name: text, dtype: object)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Dec 08 04:50:26 +0000 2021</td>\n",
       "      <td>RT @songpinganq: @Ev1HasAnOpinion @imajollyrog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed Dec 08 06:27:38 +0000 2021</td>\n",
       "      <td>@jacobqvirin @bwfmedia please jacob that is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed Dec 08 07:33:19 +0000 2021</td>\n",
       "      <td>The United States and Australia will send athl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed Dec 08 07:39:12 +0000 2021</td>\n",
       "      <td>RT @MicrobesInfo: #Bird #Flu #outbreak in #Chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed Dec 08 11:35:27 +0000 2021</td>\n",
       "      <td>@irvinethesteve I live here) \\nCame from China...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Wed Dec 08 04:50:26 +0000 2021   \n",
       "1  Wed Dec 08 06:27:38 +0000 2021   \n",
       "2  Wed Dec 08 07:33:19 +0000 2021   \n",
       "3  Wed Dec 08 07:39:12 +0000 2021   \n",
       "4  Wed Dec 08 11:35:27 +0000 2021   \n",
       "\n",
       "                                                text  \n",
       "0  RT @songpinganq: @Ev1HasAnOpinion @imajollyrog...  \n",
       "1  @jacobqvirin @bwfmedia please jacob that is th...  \n",
       "2  The United States and Australia will send athl...  \n",
       "3  RT @MicrobesInfo: #Bird #Flu #outbreak in #Chi...  \n",
       "4  @irvinethesteve I live here) \\nCame from China...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty list to hold DataFrames\n",
    "dfs_to_concat = []\n",
    "\n",
    "# List of sinophobic terms\n",
    "sinophobic_terms = ['china', 'chinese', 'sinophobia','sinophobic', 'prc', 'wuhan', 'hubei', 'beijing', 'kung flu', 'chn','cn', 'ccp', 'yellow peril', 'chink', 'chinks', \n",
    "                    'chingchong', 'ching chong', 'gook', 'chyna', 'mainland', 'mainlander', 'bugland', 'chines', \n",
    "                    'mainla', 'chinazi', 'bugmen', 'chankoro', 'insectoid']\n",
    "\n",
    "for term in sinophobic_terms:\n",
    "    filtered_df = df[df['text'].str.contains(f'\\\\b{term}\\\\b', case=False, na=False, regex=True)]\n",
    "    print(f\"Term: {term}, Count: {len(filtered_df)}\")\n",
    "    print(filtered_df['text'].head(5))  # Print the first 5 rows to inspect the content\n",
    "    dfs_to_concat.append(filtered_df)\n",
    "\n",
    "\n",
    "# Concatenate all filtered DataFrames\n",
    "final = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "\n",
    "# Remove duplicate entries\n",
    "final = final.drop_duplicates(subset=['text'])\n",
    "\n",
    "# Reset the index of the final DataFrame\n",
    "final = final.reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows of the final DataFrame\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c71b739e-beee-466f-adaa-f6846dd7a2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2299"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876caa26-9f15-4613-b7b1-6fadfb135d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"D:\\\\Sinophobia Sentiment Analysis\\\\NewFiltering\\\\IndoAfterFilter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e46469b0-f32c-4d6b-a027-a25bfe7a88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withtime = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d98f4861-8d48-43d1-8555-ede1f760479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.drop(columns=['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07ba9215",
   "metadata": {
    "id": "07ba9215"
   },
   "outputs": [],
   "source": [
    "contractionsWithAnotherInvertedComma = {\n",
    "\"ain’t\": \"am not\", \"aren’t\": \"are not\", \"can’t\": \"cannot\", \"can’t’ve\": \"cannot have\", \"’cause\": \"because\", \"could’ve\": \"could have\", \"couldn’t\": \"could not\",\n",
    "\"couldn’t’ve\": \"could not have\", \"didn’t\": \"did not\", \"doesn’t\": \"does not\", \"don’t\": \"do not\", \"hadn’t\": \"had not\", \"hadn’t’ve\": \"had not have\",\n",
    "\"hasn’t\": \"has not\", \"haven’t\": \"have not\", \"he’d\": \"he had\", \"he’d’ve\": \"he would have\", \"he’ll\": \"he will\", \"he’ll’ve\": \"he will have\", \"he’s\": \"he is\",\n",
    "\"how’d\": \"how did\", \"how’d’y\": \"how do you\", \"how’ll\": \"how will\", \"how’s\": \"how is\", \"i’d\": \"i would\", \"i’d’ve\": \"i would have\",\n",
    "\"i’ll\": \"i will\", \"i’ll’ve\": \"i will have\", \"i’m\": \"i am\", \"i’ve\": \"i have\", \"isn’t\": \"is not\", \"it’d\": \"it would\",\n",
    "\"it’d’ve\": \"it would have\", \"it’ll\": \"it will\", \"it’ll’ve\": \"it will have\", \"it’s\": \"it is\", \"let’s\": \"let us\",\n",
    "\"ma’am\": \"madam\", \"mayn’t\": \"may not\", \"might’ve\": \"might have\", \"mightn’t\": \"might not\", \"mightn’t’ve\": \"might not have\", \"must’ve\": \"must have\", \"mustn’t\": \"must not\",\n",
    "\"mustn’t’ve\": \"must not have\", \"needn’t\": \"need not\", \"needn’t’ve\": \"need not have\", \"o’clock\": \"of the clock\", \"oughtn’t\": \"ought not\", \"oughtn’t’ve\": \"ought not have\",\n",
    "\"shan’t\": \"shall not\", \"shan’t’ve\": \"shall not have\", \"she’d\": \"she would\", \"she’d’ve\": \"she would have\", \"she’ll\": \"she will\",\n",
    "\"she’ll’ve\": \"she will have\", \"she’s\": \"she is\", \"should’ve\": \"should have\", \"shouldn’t\": \"should not\", \"shouldn’t’ve\": \"should not have\",\n",
    "\"so’ve\": \"so have\", \"so’s\": \"so is\", \"that’d\": \"that would\", \"that’d’ve\": \"that would have\", \"that’s\": \"that is\", \"there’d\": \"there would\",\n",
    "\"there’d’ve\": \"there would have\", \"there’s\": \"there is\", \"they’d\": \"they would\", \"they’d’ve\": \"they would have\", \"they’ll\": \"they will\",\n",
    "\"they’ll’ve\": \"they will have\", \"they’re\": \"they are\", \"they’ve\": \"they have\", \"to’ve\": \"to have\", \"wasn’t\": \"was not\", \"we’d\": \"we would\",\n",
    "\"we’d’ve\": \"we would have\", \"we’ll\": \"we will\", \"we’ll’ve\": \"we will have\", \"we’re\": \"we are\", \"we’ve\": \"we have\", \"weren’t\": \"were not\", \"what’ll\": \"what will\",\n",
    "\"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\",\n",
    "\"when’ve\": \"when have\", \"where’d\": \"where did\", \"where’s\": \"where is\", \"where’ve\": \"where have\", \"who’ll\": \"who will\", \"who’ll’ve\": \"who will have\",\n",
    "\"who’s\": \"who is\", \"who’ve\": \"who have\", \"why’s\": \"why is\", \"why’ve\": \"why have\", \"will’ve\": \"will have\", \"won’t\": \"will not\", \"won’t’ve\": \"will not have\",\n",
    "\"would’ve\": \"would have\", \"wouldn’t\": \"would not\", \"wouldn’t’ve\": \"would not have\", \"y’all\": \"you all\", \"y’all’d\": \"you all would\", \"y’all’d’ve\": \"you all would have\",\n",
    "\"y’all’re\": \"you all are\", \"y’all’ve\": \"you all have\", \"you’d\": \"you would\", \"you’d’ve\": \"you would have\", \"you’ll\": \"you will\", \"you’ll’ve\": \"you will have\",\n",
    "\"you’re\": \"you are\", \"you’ve\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90b36cc9",
   "metadata": {
    "id": "90b36cc9"
   },
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he had\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \"he'll've\": \"he will have\", \"he's\": \"he is\",\n",
    "\"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\", \"i'll've\": \"i will have\", \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"it's\": \"it is\", \"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\", \"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\", \"so's\": \"so is\", \"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\", \"there's\": \"there is\", \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\",\n",
    "\"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\", \"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\", \"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\", \"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b24df387-a3f6-4292-aa6c-047e978329ac",
   "metadata": {
    "id": "b24df387-a3f6-4292-aa6c-047e978329ac"
   },
   "outputs": [],
   "source": [
    "abbreviations_dict = {\n",
    "    \"ccp\": \"chinese communist party\", \"cn\": \"china\", \"chn\": \"china\", \"prc\": \"peoples republic of china\",\n",
    "    \"btw\": \"by the way\", \"brb\": \"be right back\",\n",
    "    \"b4n\": \"bye for now\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"ilu\": \"i love you\",\n",
    "    \"iow\": \"in other words\",\n",
    "    \"roflol\": \"rolling on the floor laughing out loud\",\n",
    "    \"rotflmao\": \"rolling on the floor laughing my ass off\",\n",
    "    \"fb\": \"facebook\", \"ig\": \"instagram\", \"li\": \"linkedin\", \"yt\": \"youtube\", \"tw\": \"twitter\",\n",
    "    \"dm\": \"direct message\", \"mt\": \"modified tweet\", \"pm\": \"private message\", \"rt\": \"retweet\",\n",
    "    \"b2b\": \"business to business\", \"b2c\": \"business to consumer\", \"cmgr\": \"community manager\",\n",
    "    \"cms\": \"content management system\", \"cpc\": \"cost per click\", \"cpm\": \"cost per thousand impressions\",\n",
    "    \"cr\": \"conversion rate\", \"cro\": \"conversion rate optimization\", \"cta\": \"call to action\",\n",
    "    \"ctr\": \"click-through rate\", \"roi\": \"return on investment\", \"smb\": \"small and midsize businesses\",\n",
    "    \"smp\": \"social media platform\", \"smm\": \"social media marketing\", \"smo\": \"social media optimization\",\n",
    "    \"solomo\": \"social, local and mobile\", \"srp\": \"social relationship platform\", \"tos\": \"terms of service\",\n",
    "    \"ugc\": \"user-generated content\", \"api\": \"application programming interface\", \"cx\": \"customer experience\",\n",
    "    \"esp\": \"email service provider\", \"ga\": \"google analytics\", \"isp\": \"internet service provider\",\n",
    "    \"pv\": \"page views\", \"rss\": \"really simple syndication\", \"saas\": \"software as a service\",\n",
    "    \"sem\": \"search engine marketing\", \"seo\": \"search engine optimization\", \"sov\": \"share of voice\",\n",
    "    \"ui\": \"user interface\", \"url\": \"uniform resource locator\", \"uv\": \"unique views\", \"ux\": \"user experience\",\n",
    "    \"afaik\": \"as far as i know\", \"ama\": \"ask me anything\", \"btaim\": \"be that as it may\",\n",
    "    \"bts\": \"behind the scenes\", \"dae\": \"does anyone else\", \"dyk\": \"did you know\",\n",
    "    \"eli5\": \"explain like i’m five\", \"fbf\": \"flashback friday\", \"fbo\": \"facebook official\",\n",
    "    \"ff\": \"follow friday\", \"fomo\": \"fear of missing out\", \"ftfy\": \"fixed that for you\",\n",
    "    \"ftw\": \"for the win\", \"g2g\": \"got to go\", \"gg\": \"good game\", \"gtr\": \"got to run\",\n",
    "    \"hbd\": \"happy birthday\", \"hifw\": \"how i feel when\", \"hmb\": \"hit me back\", \"hmu\": \"hit me up\",\n",
    "    \"ht\": \"hat tip\", \"h/t\": \"hat tip\", \"hth\": \"here to help\", \"icymi\": \"in case you missed it\",\n",
    "    \"idc\": \"i don’t care\", \"idk\": \"i don’t know\", \"ikr\": \"i know, right?\", \"ily\": \"i love you\",\n",
    "    \"imho\": \"in my humble opinion\", \"imo\": \"in my opinion\", \"irl\": \"in real life\", \"jk\": \"just kidding\",\n",
    "    \"lmao\": \"laughing my ass off\", \"lmk\": \"let me know\", \"lms\": \"like my status\",\n",
    "    \"lol\": \"laughing out loud\", \"mcm\": \"man crush monday\", \"mfw\": \"my face when\",\n",
    "    \"mtfbwy\": \"may the force be with you\", \"nbd\": \"no big deal\", \"nm\": \"not much\",\n",
    "    \"nsfw\": \"not safe for work\", \"nvm\": \"never mind\", \"oh\": \"overheard\", \"omw\": \"on my way\",\n",
    "    \"ootd\": \"outfit of the day\", \"op\": \"original poster\", \"otp\": \"one true pairing\", \"ppl\": \"people\",\n",
    "    \"rofl\": \"rolling on the floor laughing\", \"roflmao\": \"rolling on the floor laughing my ass off\",\n",
    "    \"sfw\": \"safe for work\", \"smh\": \"shaking my head\", \"tbh\": \"to be honest\", \"tbbh\": \"to be brutally honest\",\n",
    "    \"tbt\": \"throwback thursday\", \"tfw\": \"that feeling when\", \"tgif\": \"thank god it’s friday\",\n",
    "    \"til\": \"today i learned\", \"tl;dr\": \"too long; didn’t read\", \"tmi\": \"too much information\",\n",
    "    \"wbu\": \"what about you?\", \"wbw\": \"way back wednesday\", \"wfh\": \"work from home\", \"yolo\": \"you only live once\",\n",
    "    \"afk\": \"away from keyboard\", \"asap\": \"as soon as possible\", \"atk\": \"at the keyboard\",\n",
    "    \"atm\": \"at the moment\", \"a3\": \"anytime, anywhere, anyplace\", \"bak\": \"back at keyboard\",\n",
    "    \"bbl\": \"be back later\", \"bbs\": \"be back soon\", \"bfn\": \"bye for now\", \"brt\": \"be right there\",\n",
    "    \"b4\": \"before\", \"cu\": \"see you\", \"cul8r\": \"see you later\", \"cya\": \"see you\", \"faq\": \"frequently asked questions\",\n",
    "    \"fc\": \"fingers crossed\", \"fwiw\": \"for what it's worth\", \"gal\": \"get a life\", \"gn\": \"good night\",\n",
    "    \"gmta\": \"great minds think alike\", \"gr8\": \"great!\", \"g9\": \"genius\", \"ic\": \"i see\", \"icq\": \"i seek you\",\n",
    "    \"kiss\": \"keep it simple, stupid\", \"ldr\": \"long distance relationship\", \"ltns\": \"long time no see\",\n",
    "    \"l8r\": \"later\", \"mte\": \"my thoughts exactly\", \"m8\": \"mate\", \"nrn\": \"no reply necessary\", \"oic\": \"oh i see\",\n",
    "    \"pita\": \"pain in the a..\", \"prt\": \"party\", \"prw\": \"parents are watching\", \"qpsa\": \"que pasa?\",\n",
    "    \"sk8\": \"skate\", \"stats\": \"your sex and age\", \"asl\": \"age, sex, location\", \"thx\": \"thank you\",\n",
    "    \"ttfn\": \"ta-ta for now!\", \"ttyl\": \"talk to you later\", \"u\": \"you\", \"u2\": \"you too\", \"u4e\": \"yours for ever\",\n",
    "    \"wb\": \"welcome back\", \"wtf\": \"what the f...\", \"wtg\": \"way to go!\", \"wuf\": \"where are you from?\",\n",
    "    \"w8\": \"wait...\", \"7k\": \"sick:-d laugher\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "256c9da9-0c0b-4423-8455-a700d9a5f5f2",
   "metadata": {
    "id": "256c9da9-0c0b-4423-8455-a700d9a5f5f2"
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "class preprocess():\n",
    "    def __init__(self, df, contractions, otherContractions):\n",
    "        self.df = df\n",
    "        self.contractions = contractions\n",
    "        self.otherContractions = otherContractions\n",
    "\n",
    "    def lower(self, tweet):\n",
    "        return tweet.lower()\n",
    "\n",
    "    def abbreviate(self, tweet):\n",
    "        tweet_tokens = tweet.split(' ')\n",
    "        for i, token in enumerate(tweet_tokens):\n",
    "            cleaned_token = re.sub('[^a-zA-Z0-9-_.]', '', token)\n",
    "            if cleaned_token.lower() in abbreviations_dict:\n",
    "                tweet_tokens[i] = abbreviations_dict[cleaned_token.lower()]\n",
    "        return ' '.join(tweet_tokens)\n",
    "\n",
    "    def expand(self, tweet):\n",
    "        for word in tweet.split():\n",
    "            if word in self.contractions.keys():\n",
    "                tweet = tweet.replace(word, self.contractions[word])\n",
    "            elif word in self.otherContractions.keys():\n",
    "                tweet = tweet.replace(word, self.otherContractions[word])\n",
    "        return tweet\n",
    "\n",
    "    def emoji2text(self, tweet):\n",
    "        emojis = demoji.findall(tweet)\n",
    "        new_tweet = []\n",
    "        for word in tweet.split():\n",
    "            if word in emojis.keys():\n",
    "                tweet = tweet.replace(word, emojis[word])\n",
    "                new_tweet.append(emojis[word])\n",
    "            wordmojis = demoji.findall(word)\n",
    "            for char in word:\n",
    "                if char in wordmojis.keys():\n",
    "                    tweet = tweet.replace(word, wordmojis[char])\n",
    "\n",
    "        return tweet\n",
    "\n",
    "    def remove_hashtags(self, tweet):\n",
    "        return re.sub(r'\\#w+', '', tweet)\n",
    "\n",
    "    def remove_mentions(self, tweet):\n",
    "        for word in tweet.split():\n",
    "            if word[0] == '@':\n",
    "                tweet = tweet.replace(word, '')\n",
    "        return tweet\n",
    "\n",
    "    def remove_punctuations(self, tweet):\n",
    "        punct = string.punctuation\n",
    "        trantab = str.maketrans(punct, len(punct)*' ')\n",
    "        return tweet.translate(trantab)\n",
    "\n",
    "    def remove_url(self, tweet):\n",
    "        return re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', tweet, flags = re.MULTILINE)\n",
    "\n",
    "    def preprocess_tweet(self, tweet):\n",
    "        tweet = self.lower(tweet)\n",
    "        tweet = self.abbreviate(tweet)\n",
    "        tweet = self.expand(tweet)\n",
    "        tweet = self.emoji2text(tweet)\n",
    "        tweet = self.remove_mentions(tweet)\n",
    "        tweet = self.remove_url(tweet)\n",
    "        tweet = self.remove_hashtags(tweet)\n",
    "        tweet = self.remove_punctuations(tweet)\n",
    "\n",
    "        return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a454bf6e-7d8d-4f1f-acd1-d978d56a207a",
   "metadata": {
    "id": "a454bf6e-7d8d-4f1f-acd1-d978d56a207a"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "pp_class = preprocess(final, contractions, contractionsWithAnotherInvertedComma)\n",
    "final['text'] = final['text'].apply(lambda x : pp_class.preprocess_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f121faf-8629-4e39-95d3-ed74fe2c9390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bruteGen(tweet):\n",
    "    tweet = tweet.replace(\"indiavscorona\", \"india versus coronavirus\")\n",
    "    tweet = tweet.replace(\"outbreakindia\", \"outbreak india\")\n",
    "    tweet = tweet.replace(\"real”\", \"real\")\n",
    "    tweet = tweet.replace(\"mutra\", \"urine\")\n",
    "    tweet = tweet.replace(\"fakenews\", \"fake news\")\n",
    "    tweet = tweet.replace(\"“omg\", \"oh my god\")\n",
    "    tweet = tweet.replace(\"“damn\", \"damn\")\n",
    "    tweet = tweet.replace(\"god’s\", \"gods\")\n",
    "    tweet = tweet.replace(\"lockdownextension\", \"lockdown extension\")\n",
    "    tweet = tweet.replace(\"कोरोना\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"indiathanks\", \"india thanks\")\n",
    "    tweet = tweet.replace(\"coronacoronavirus\", \"coronavirus\")\n",
    "    tweet = tweet.replace('coronavirusinsa', \"coronavirus in south africa\")\n",
    "    tweet = tweet.replace('coronaviruscanada', 'coronavirus canada')\n",
    "    tweet = tweet.replace('coronavirusau', 'coronavirus australia')\n",
    "    tweet = tweet.replace('coronavirusaus', 'coronavirus australia')\n",
    "    tweet = tweet.replace('cuomoprimetime', 'new york governor prime time')\n",
    "    tweet = tweet.replace('letsfightcoronavirus', 'let us fight coronavirus')\n",
    "    tweet = tweet.replace(\"covid 19\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"covid19\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"covid\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"aprilfoolsday\", \"april fools day\")\n",
    "    tweet = tweet.replace(\"covid-19\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"stayathome\", \"stay at home\")\n",
    "    tweet = tweet.replace(\"“april\", \"april\")\n",
    "    tweet = tweet.replace(\"“i\", \"i\")\n",
    "    tweet = tweet.replace(\"aprilfools\", \"april fools\")\n",
    "    tweet = tweet.replace(\"coronavirusoutbreak\", \"coronavirus outbreak\")\n",
    "    tweet = tweet.replace(\"virus-19\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"fool’s\", \"fools\")\n",
    "    tweet = tweet.replace(\"what’s\", \"what is\")\n",
    "    tweet = tweet.replace(\"coronavirus”\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"fools”\", \"fools\")\n",
    "    tweet = tweet.replace(\"stayhome\", \"stay home\")\n",
    "    tweet = tweet.replace(\"quarantinelife\", \"quarantine life\")\n",
    "    tweet = tweet.replace(\"tablighijamaat\", \"muslims\")\n",
    "    tweet = tweet.replace(\"corona”\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"fauci\", \"physician\")\n",
    "    tweet = tweet.replace(\"april’s\", \"april\")\n",
    "    tweet = tweet.replace(\"pmkcallscurfewextension\", \"prime minister calls for curfew extension\")\n",
    "    tweet = tweet.replace(\"“virus\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"virus”\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"“corona\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"coronavirustruth\", \"coronavirus truth\")\n",
    "    tweet = tweet.replace(\"socialdistancing\", \"social distancing\")\n",
    "    tweet = tweet.replace(\"homestaysafe\", \"home stay safe\")\n",
    "    tweet = tweet.replace(\"“coronavirus\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"coronavirusupdate\", \"coronavirus update\")\n",
    "    tweet = tweet.replace(\"virusvirus\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"coronaviruspandemic\", \"coronavirus pandemic\")\n",
    "    tweet = tweet.replace(\"thelockdown\", \"the lockdown\")\n",
    "    tweet = tweet.replace(\"nizamuddin\", \"delhi\")\n",
    "    tweet = tweet.replace(\"trump’s\", \"donald trump\")\n",
    "    tweet = tweet.replace(\"“the\", \"the\")\n",
    "    tweet = tweet.replace(\"virus2019\", \"coronavirus\")\n",
    "    tweet = tweet.replace(\"indiafightscorona\", \"india fights coronavirus\")\n",
    "    tweet = tweet.replace(\"homesavelives\", \"home save lives\")\n",
    "    tweet = tweet.replace(\"everyone’s\", \"everyone\")\n",
    "    tweet = tweet.replace(\"coronariskforprisoners\", \"coronavirus risk for prisoners\")\n",
    "    tweet = tweet.replace(\"coronavirususa\", \"coronavirus usa\")\n",
    "    tweet = tweet.replace(\"tablighi\", \"mosque\")\n",
    "    tweet = tweet.replace(\"delhimarkaz\", \"delhi mosque\")\n",
    "    tweet = tweet.replace(\"coronajihad\", \"coronavirus struggle\")\n",
    "    tweet = tweet.replace(\"coronajihaad\", \"coronavirus struggle\")\n",
    "    tweet = tweet.replace(\"aprilfool\", \"april fool\")\n",
    "    tweet = tweet.replace(\"trumppressconference\", \"trump press conference\")\n",
    "    tweet = tweet.replace(\"i’m\", \"i am\")\n",
    "    tweet = tweet.replace(\"tigerking\", \"tiger king\")\n",
    "    tweet = tweet.replace(\"it’s\", \"it is\")\n",
    "    tweet = tweet.replace(\"trumpvirus\", \"trump virus\")\n",
    "    tweet = tweet.replace(\"today’s\", \"today is\")\n",
    "    tweet = tweet.replace(\"“you\", \"you\")\n",
    "    tweet = tweet.replace(\"“a\", \"a\")\n",
    "    tweet = tweet.replace(\"fools’\", \"fools\")\n",
    "    tweet = tweet.replace(\"rtgnews\", \"news\")\n",
    "    tweet = tweet.replace(\"19india\", \"india\")\n",
    "    tweet = tweet.replace(\"coronavirusindia\", \"coronavirus india\")\n",
    "    tweet = tweet.replace(\"y’all\", \"you all\")\n",
    "    tweet = tweet.replace(\"मीडिया\", \"media\")\n",
    "    tweet = tweet.replace(\"here’s\", \"here is\")\n",
    "    tweet = tweet.replace(\"“we\", \"we\")\n",
    "    tweet = tweet.replace(\"“fuck\", \"fuck\")\n",
    "    tweet = tweet.replace(\"flattenthecurve\", \"flatten the curve\")\n",
    "    tweet = tweet.replace(\"jammuandkashmir\", \"jammu and kashmir\")\n",
    "    tweet = tweet.replace(\"chriscuomo\", \"new york governor\")\n",
    "    tweet = tweet.replace(\"‘april\", \"april\")\n",
    "    tweet = tweet.replace(\"dranbumani\", \"doctor\")\n",
    "    tweet = tweet.replace(\"tndemandsmasstesting\", \"tamil nadu demands mass testing\")\n",
    "    tweet = tweet.replace(\"tabligi\", \"muslims\")\n",
    "    tweet = tweet.replace(\"don’t\", \"do not\")\n",
    "    tweet = tweet.replace(\"वायरस\", \"virus\")\n",
    "    tweet = tweet.replace(\"letsfightvirus\", \"let us fight virus\")\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c1eaed9-7318-43fe-bcb8-1bf7f387baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final['text'] = final['text'].apply(lambda x : bruteGen(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad5973ce-2151-45fd-b658-4adc38e9ff9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "ad5973ce-2151-45fd-b658-4adc38e9ff9a",
    "outputId": "48eb9c18-e838-401a-cc37-d940255da3f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                    text\n",
       "0     retweet      guangxi province pingxiang city  ...\n",
       "1       please jacob that is the best decision from ...\n",
       "2     the united states and australia will send athl...\n",
       "3     retweet   bird  flu  outbreak in  china on top...\n",
       "4      i live here  \\ncame from china for holiday ri...\n",
       "...                                                 ...\n",
       "2294  retweet  the latest wave  driven by the highly...\n",
       "2295  retweet  thanks for speaking out loudly to sup...\n",
       "2296    i am a mainlander so all my relatives live i...\n",
       "2297   gt  double vaccinated mainlander getting coro...\n",
       "2298  i take it back when i say the entire indie gam...\n",
       "\n",
       "[2299 rows x 1 columns]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd42e400-c007-46bf-b10c-53a297446768",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bd42e400-c007-46bf-b10c-53a297446768",
    "outputId": "e10e384c-7030-47fb-8ae2-45c5f5ed846a"
   },
   "outputs": [],
   "source": [
    "final.to_csv(\"D:\\\\Sinophobia Sentiment Analysis\\\\NewFiltering\\\\IndoAfterpreprocess.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2529f8c-88d9-453b-8e73-d0015f372b41",
   "metadata": {
    "id": "d2529f8c-88d9-453b-8e73-d0015f372b41"
   },
   "outputs": [],
   "source": [
    "labels = ['Optimistic', 'Thankful', 'Empathetic', 'Pessimistic',\n",
    "       'Anxious', 'Sad', 'Annoyed', 'Denial', 'Official report', 'Joking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4525733d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "4525733d",
    "outputId": "57db59d9-c373-407f-fe7e-f79bebbe5da4"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86a46e47",
   "metadata": {
    "id": "86a46e47"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Tweet'] = final['text']\n",
    "values = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] * len(final)\n",
    "df[labels] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02909eb7-8051-4503-9f5c-4ea28bc97b2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "02909eb7-8051-4503-9f5c-4ea28bc97b2e",
    "outputId": "da3cb534-5204-4470-c534-38acde5448b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Optimistic</th>\n",
       "      <th>Thankful</th>\n",
       "      <th>Empathetic</th>\n",
       "      <th>Pessimistic</th>\n",
       "      <th>Anxious</th>\n",
       "      <th>Sad</th>\n",
       "      <th>Annoyed</th>\n",
       "      <th>Denial</th>\n",
       "      <th>Official report</th>\n",
       "      <th>Joking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>retweet      guangxi province pingxiang city  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>please jacob that is the best decision from ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the united states and australia will send athl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>retweet   bird  flu  outbreak in  china on top...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i live here  \\ncame from china for holiday ri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>retweet  the latest wave  driven by the highly...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>retweet  thanks for speaking out loudly to sup...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>i am a mainlander so all my relatives live i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>gt  double vaccinated mainlander getting coro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>i take it back when i say the entire indie gam...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2299 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Optimistic  Thankful  \\\n",
       "0     retweet      guangxi province pingxiang city  ...           0         0   \n",
       "1       please jacob that is the best decision from ...           0         0   \n",
       "2     the united states and australia will send athl...           0         0   \n",
       "3     retweet   bird  flu  outbreak in  china on top...           0         0   \n",
       "4      i live here  \\ncame from china for holiday ri...           0         0   \n",
       "...                                                 ...         ...       ...   \n",
       "2294  retweet  the latest wave  driven by the highly...           0         0   \n",
       "2295  retweet  thanks for speaking out loudly to sup...           0         0   \n",
       "2296    i am a mainlander so all my relatives live i...           0         0   \n",
       "2297   gt  double vaccinated mainlander getting coro...           0         0   \n",
       "2298  i take it back when i say the entire indie gam...           0         0   \n",
       "\n",
       "      Empathetic  Pessimistic  Anxious  Sad  Annoyed  Denial  Official report  \\\n",
       "0              0            0        0    0        0       0                0   \n",
       "1              0            0        0    0        0       0                0   \n",
       "2              0            0        0    0        0       0                0   \n",
       "3              0            0        0    0        0       0                0   \n",
       "4              0            0        0    0        0       0                0   \n",
       "...          ...          ...      ...  ...      ...     ...              ...   \n",
       "2294           0            0        0    0        0       0                0   \n",
       "2295           0            0        0    0        0       0                0   \n",
       "2296           0            0        0    0        0       0                0   \n",
       "2297           0            0        0    0        0       0                0   \n",
       "2298           0            0        0    0        0       0                0   \n",
       "\n",
       "      Joking  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "2294       0  \n",
       "2295       0  \n",
       "2296       0  \n",
       "2297       0  \n",
       "2298       0  \n",
       "\n",
       "[2299 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b4515b1-d9f8-4691-8a40-5219d9bcd8b2",
   "metadata": {
    "id": "1b4515b1-d9f8-4691-8a40-5219d9bcd8b2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "   def __init__(self,df,tokenizer,max_len):\n",
    "     self.df = df\n",
    "     self.tokenizer = tokenizer\n",
    "     self.max_len = max_len\n",
    "     self.title = self.df['Tweet']\n",
    "     self.targets = self.df[labels].values\n",
    "\n",
    "   def __len__(self):\n",
    "     return len(self.title)\n",
    "\n",
    "   def __getitem__(self,index):\n",
    "     title = str(self.title[index])\n",
    "     title = \" \".join(title.split())\n",
    "\n",
    "     inputs = self.tokenizer.encode_plus(\n",
    "         title,\n",
    "         None,\n",
    "         add_special_tokens=True,\n",
    "         max_length=self.max_len,\n",
    "         padding='max_length',\n",
    "         return_token_type_ids=True,\n",
    "         truncation=True,\n",
    "         return_attention_mask=True,\n",
    "         return_tensors='pt'\n",
    "     )\n",
    "     return {\n",
    "         'input_ids':inputs['input_ids'].flatten(),\n",
    "         'attention_mask':inputs['attention_mask'].flatten(),\n",
    "         'token_type_ids':inputs['token_type_ids'].flatten(),\n",
    "         'targets':torch.FloatTensor(self.targets[index])\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c63b8ddb-04c5-4357-98be-43d7f8c2aafa",
   "metadata": {
    "id": "c63b8ddb-04c5-4357-98be-43d7f8c2aafa"
   },
   "outputs": [],
   "source": [
    "MAX_LEN=256\n",
    "_dataset = CustomDataset(df, tokenizer, MAX_LEN)\n",
    "_data_loader = torch.utils.data.DataLoader(\n",
    "    _dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=8,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc1c4de2-18da-44c1-9dae-ffab21e5313b",
   "metadata": {
    "id": "bc1c4de2-18da-44c1-9dae-ffab21e5313b"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7df4df5f-9f7e-409f-beda-7546ab13d765",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 902,
     "referenced_widgets": [
      "98044adc3f554490bb622f6b98563760",
      "1f787c1c68e04f248dca364ff388e242",
      "c72188bc55604e83a3ee05c442356799",
      "ef54033832254f00bc94bba0e16d2e7b",
      "cd9d4fbf0f094d2a89a843ddf100427e",
      "505b3ca46d754dbbb0cfedbb0f7e1a95",
      "d2e686f21bf64b1f9c506763db900de3",
      "cd00f7fd0c784ea58654a0bb3f7a4e59",
      "2786ab14b0d548388f234ff30df73b95",
      "c50d3410574243ab8a909c30197eec4e",
      "649c639f49c84ddbb42399f0f1b9f4ae"
     ]
    },
    "id": "7df4df5f-9f7e-409f-beda-7546ab13d765",
    "outputId": "6be243aa-4846-44d0-d7f6-592d326e34f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (layer1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Dropout(p=0.3, inplace=False)\n",
       "  (layer3): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.layer2 = torch.nn.Dropout(0.3)\n",
    "        self.layer3 = torch.nn.Linear(768, 10)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids, return_dict = False):\n",
    "        unw, out_1 = self.layer1(ids, attention_mask = mask, token_type_ids = token_type_ids)[0], self.layer1(ids, attention_mask = mask, token_type_ids = token_type_ids)[1]\n",
    "        out_2 = self.layer2(out_1)\n",
    "        out_final = self.layer3(out_2)\n",
    "        return out_final\n",
    "\n",
    "\n",
    "model = BERT()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ZQbVtaIWAnlW",
   "metadata": {
    "id": "ZQbVtaIWAnlW"
   },
   "outputs": [],
   "source": [
    "model = torch.load(\"D:\\\\Sinophobia Sentiment Analysis\\\\Transformers4.10Bertmodel2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d4b235-d54d-4f86-8fab-720581f961d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d9d4b235-d54d-4f86-8fab-720581f961d2",
    "outputId": "a1c74c66-1838-4ad0-dcc2-a0fe3f613158"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "bert_outputs = []\n",
    "with torch.no_grad():\n",
    "\n",
    "  for index, batch in enumerate(_data_loader):\n",
    "         input_ids = batch['input_ids'].to(device, dtype=torch.long)\n",
    "         attention_mask = batch['attention_mask'].to(device, dtype=torch.long)\n",
    "         token_type_ids = batch['token_type_ids'].to(device, dtype=torch.long)\n",
    "         targets =  batch['targets'].to(device, dtype=torch.float)\n",
    "         outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "         bert_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9c36a8-07de-449d-b0a0-efb553bceb3e",
   "metadata": {
    "id": "bc9c36a8-07de-449d-b0a0-efb553bceb3e"
   },
   "outputs": [],
   "source": [
    "test_outputs = np.array(bert_outputs)\n",
    "\n",
    "for i in range(test_outputs.shape[0]):\n",
    "    for j in range(test_outputs.shape[1]):\n",
    "        if test_outputs[i][j] >= 0.5: test_outputs[i][j] = 1\n",
    "        else: test_outputs[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa8563-7186-4523-b14c-87d60497540c",
   "metadata": {
    "id": "a6fa8563-7186-4523-b14c-87d60497540c"
   },
   "outputs": [],
   "source": [
    "df[labels] = test_outputs.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64259cdf-b77d-4161-b1d0-02c56fcc6dcc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "id": "64259cdf-b77d-4161-b1d0-02c56fcc6dcc",
    "outputId": "5540fcc4-a2d7-404c-8f34-90c763559477"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e5f52-9a20-42a8-82cc-52977f77a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withtime.reset_index(drop=True, inplace=True)\n",
    "df_withtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf76702-e80f-42cf-a09b-35415d2518c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Indo = pd.DataFrame()\n",
    "Indo['Tweet'] = df['Tweet']\n",
    "Indo['text'] = df_withtime['text']\n",
    "Indo['date'] = df_withtime['created_at']\n",
    "Indo[labels] = df[labels]\n",
    "Indo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c481d926-bbcc-4a26-89cc-3a96e6896ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Indo.to_csv(\"D:\\\\Sinophobia Sentiment Analysis\\\\NewFiltering\\\\Result\\\\Indo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cff1ec-394c-4c3b-a713-9e08dcbd3539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1f787c1c68e04f248dca364ff388e242": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_505b3ca46d754dbbb0cfedbb0f7e1a95",
      "placeholder": "​",
      "style": "IPY_MODEL_d2e686f21bf64b1f9c506763db900de3",
      "value": "Downloading: 100%"
     }
    },
    "2786ab14b0d548388f234ff30df73b95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "505b3ca46d754dbbb0cfedbb0f7e1a95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "649c639f49c84ddbb42399f0f1b9f4ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98044adc3f554490bb622f6b98563760": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f787c1c68e04f248dca364ff388e242",
       "IPY_MODEL_c72188bc55604e83a3ee05c442356799",
       "IPY_MODEL_ef54033832254f00bc94bba0e16d2e7b"
      ],
      "layout": "IPY_MODEL_cd9d4fbf0f094d2a89a843ddf100427e"
     }
    },
    "c50d3410574243ab8a909c30197eec4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c72188bc55604e83a3ee05c442356799": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd00f7fd0c784ea58654a0bb3f7a4e59",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2786ab14b0d548388f234ff30df73b95",
      "value": 440473133
     }
    },
    "cd00f7fd0c784ea58654a0bb3f7a4e59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd9d4fbf0f094d2a89a843ddf100427e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2e686f21bf64b1f9c506763db900de3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef54033832254f00bc94bba0e16d2e7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c50d3410574243ab8a909c30197eec4e",
      "placeholder": "​",
      "style": "IPY_MODEL_649c639f49c84ddbb42399f0f1b9f4ae",
      "value": " 420M/420M [00:07&lt;00:00, 70.0MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
